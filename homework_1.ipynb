{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 - Slow general algorithms for sequence labeling\n",
    "\n",
    "For homework 1, we will mainly be looking at a contrived task described below.  In this first homework, you will use slow but general algorithms.  They could be applied to *any* finite sequence problem, since they do not take advantage of any special problem structure.\n",
    "\n",
    "The coding problems in this assignment are designed to be fairly small with each taking around **5-20 lines of code**.  Throughout this assignment you will see parameters `xx`, `yy`, `oo`, `aa`, which correspond to  $\\mathbf{x},\n",
    "\\mathbf{y}, \\mathbf{o}, \\mathbf{a}$ from [the formalisms document](https://seq2class.github.io/scribe-notes/formalisms.pdf): the doubled letter is meant to suggest that the variable represents a string.  So `xx` is the input string, `yy` ranges over possible output strings, `oo` is a (partial) observation of the output string, and `aa` ranges over over possible decisions (predictions or other plans) that our system can choose.\n",
    "\n",
    "## Task overview\n",
    "\n",
    "For this assignment we are predicting which vowels in a word are stressed.\n",
    "In the (made-up) natural language used in our dataset, every vowel sound is \n",
    "represented by one of the letters `aeiou`, and we will use `AEIOU`\n",
    "to indicate their stressed versions.\n",
    "\n",
    "Following the notation defined so far, the input sequence $\\mathbf{x}$ is our input\n",
    "word (with no capitalization).  Each possible output $\\mathbf{y}$ \n",
    "contains the same sequence of letters as $\\mathbf{x}$, but with some of them \n",
    "`cApitalIzed` to indicate stress.  Therefore, if $\\mathbf{x}$ contains $m$ vowels, \n",
    "then $|\\mathcal{Y}_{\\mathbf{x}}| = 2^m$.  Sometimes, however, this exponentially\n",
    "large space gets reduced because for *some* vowels, we observe whether they are \n",
    "stressed or unstressed.  The observation is a string $\\mathbf{o}$ that is \n",
    "a version of $\\mathbf{y}$ with some of the vowels already given correctly \n",
    "as capital or lowercase, but unobserved vowels replaced with `?`.  So if \n",
    "$\\mathbf{o}$ contains $n$ question marks (where $0 \\leq n \\leq m$), \n",
    "then $|\\mathcal{Y}_{\\mathbf{x,o}}| = 2^n$.\n",
    "\n",
    "\n",
    "### Sample inputs and outputs\n",
    "| $\\mathbf{x}$ | $\\mathbf{o}$ | $\\mathbf{y} \\in \\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}$ | $\\mathbf{y} \\notin \\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}$ (illegal)|\n",
    "|:-------------:|:------------:|:---------------------:|:--------------------|\n",
    "| `helilela` | `h?lil?l?` | `helilela` | `Helilela` |\n",
    "| | | `helilelA` | `helIlela` |\n",
    "| | | `hElilelA` | ... |\n",
    "| | |    ...     |     |\n",
    "| `idonotul` | `?don?t?l` | `IdonotUl` | `idOnotUl` |\n",
    "| | | ... | ... |\n",
    "\n",
    "## Assignment Instructions\n",
    "\n",
    "Follow through the assignment in order.  Each text cell will provide details about the task and explain what is expected.  Inside of code blocks, you will see `### STUDENTS START` to indicate where you are expected to edit the cell and fill in some code.  There are also a few short-answer questions throughout the assignment.  These are marked in red with <span style='color:red'>FILL IN</span>; again, edit the cell to give your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from collections import namedtuple\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "Data_type = namedtuple('Data', ['xx', 'oo', 'yy'])\n",
    "\n",
    "def iterate_data(filename='train', *, max_examples=None):\n",
    "    file = open(filename+'.tsv')\n",
    "    for n, row in enumerate(csv.DictReader(file, delimiter='\\t')):\n",
    "        if max_examples and n >= max_examples:\n",
    "            break\n",
    "        yield Data_type(\n",
    "            xx=tuple(row['xx']),\n",
    "            oo=tuple(row['oo']) if 'oo' in row else None,\n",
    "            yy=tuple(row['yy']) if 'yy' in row else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start by looking at the data ...\n",
    "\n",
    "Our *strings* are sequences of symbols from our alphabet, represented as Python tuples.  Although our symbols in this problem are letters, they might be words in future problems, which is why we don't use raw Python strings.\n",
    "\n",
    "Each example consists of a triple `(xx,oo,yy)` where the observation string `oo` may include the special symbol `?`.\n",
    "* A **training example** may specify either \n",
    "  * `oo=None` and `yy` is the fully observed output\n",
    "  * `yy=None` and `oo` is a partial observation of the output (see formalisms.pdf, \"Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iterate_data()   # uses training set by default\n",
    "print(next(itr))       # look at the first example in our training set\n",
    "next(itr)              # look at the second example in our training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A **test example** consists of a triple `(xx,oo,yy)`, where `yy` is the correct answer.\n",
    "  The prediction rule will be given `(xx,oo)` and asked to predict `yy`.\n",
    "  * Usually `oo=None`, so the rule must simply predict `yy` from `xx`.  \n",
    "  * However, if `oo` is specified, this informs the predictor that the true `yy` is compatible with `oo`, \n",
    "    which should improve the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iterate_data('dev')   # okay to peek at the development dataset (but not the real test data!)\n",
    "print(next(itr))            # oo as partially observed output\n",
    "next(itr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the task\n",
    "\n",
    "Here is the base interface that we will be extending for the remainder of this homework.\n",
    "All of our methods are defined with a `*` argument, like this:\n",
    "```python\n",
    "def mymethod(self, *, xx, oo=None, yy):\n",
    "    pass   \n",
    "```\n",
    "The `,*,` prevents the parameters `xx, oo, yy` from being passed as positional arguments; instead they must be passed as keyword arguments.  This makes the code easier to read, and prevents errors due to accidentally specifying the arguments in the wrong order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TaskSetting` defines the environment in which we are operating, methods such as `iterate_y` and `iterate_yy` defines the output $\\mathcal{Y}$.  The method `reward` defines the the environment's reward function $R(\\mathbf{a} \\mid \\mathbf{x}, \\mathbf{y})$ that returns how good our prediction $a$ was given the true answer is $y$.  We will start implementing the methods on this class in the [first problem](#Problem_stresstask).\n",
    "<a id=\"TaskSetting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSetting(object):\n",
    "    \"\"\"\n",
    "    Base class for our task.\n",
    "    Defines the domain of YY, and our actions AA.  \n",
    "    It also defines the reward function that we are trying to maximzie \n",
    "    \"\"\"\n",
    "    \n",
    "    def iterate_yy(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        Returns an iterator over legal `yy` sequences (represented as tuples).  \n",
    "        If an observation `oo` is specified, restricts to `yy` sequences that \n",
    "        are consistent with `oo`.\n",
    "        This method *defines* the space of output strings that we will consider \n",
    "        (although some of those could turn out to have probability 0).\n",
    "        Usually it is implemented by calling `self.iterate_y`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()     \n",
    "        \n",
    "    def iterate_y(self, *, xx, oo=None, yy_prefix):\n",
    "        \"\"\"\n",
    "        Returns an iterator over legal next characters of `yy`.\n",
    "        In other words, returns all characters `y` such that\n",
    "        the concatenation `y_prefix + y` is a prefix of some\n",
    "        output `yy` that is legal given input string `xx` \n",
    "        and observable `oo`. \n",
    "        (This set is discussed in formalisms.pdf, \"Restricting summations to the output space\".)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def iterate_aa(self, *, xx):\n",
    "        \"\"\"\n",
    "        Returns an iterator over plans that are allowed for input `xx`.\n",
    "        The default implementation just calls `iterate_yy(xx=xx)`, which is \n",
    "        appropriate for prediction tasks where the plans simply correspond \n",
    "        to predicting the different outputs.  This can be overridden for\n",
    "        other kinds of decision tasks.\n",
    "        (See formalisms.pdf, \"Decision theory\" and \"More decision theory\".)\n",
    "        \"\"\"\n",
    "        yield from self.iterate_yy(xx=xx)\n",
    "        \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        \"\"\"\n",
    "        Return the reward that plan `aa` will get on input `xx` if the true answer is `yy`.\n",
    "        This method *defines* the reward function.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ProbabilityModel` defines $P(\\mathbf{y} \\mid \\mathbf{x})$.  It does this by defining a `score` function which corresponds to $G(\\mathbf{x}, \\mathbf{y})$ as well as functions to train and sample from our distribution.  We have given you a partial implementation of this class [below](#Problem_linearstressmodel) which you will fill in.\n",
    "Because our probability model must compute probabilities $P(\\mathbf{y} \\mid \\mathbf{x})$, it needs to be able to enumerate the domain of $\\mathbf{y} \\in \\mathcal{Y}$, and thus has the task model defined above as `self.task`.\n",
    "<a id=\"ProbabilityModel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilityModel(object):\n",
    "    \"\"\"\n",
    "    Base class for our probability model P_\\theta(y | x, o).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task):\n",
    "        assert isinstance(task, TaskSetting)\n",
    "        self.task = task\n",
    "        self.initialize_params()\n",
    "    \n",
    "    def initialize_params(self):\n",
    "        \"\"\"\n",
    "        Reset the model parameters to their start state.\n",
    "        \"\"\"\n",
    "        # by default there are no parameters to initialize\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\"\n",
    "        Return a copy of the parameter vector for this model\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @params.setter\n",
    "    def params(self, params_vec):\n",
    "        \"\"\"\n",
    "        Update the parameters for the model given vector params_vec\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def score(self, *, yy, xx):\n",
    "        \"\"\"\n",
    "        Return the score G(`yy`, `xx`) with respect to the params.\n",
    "        By default use `score_with_gradient` and only return the score\n",
    "        \"\"\"\n",
    "        score, gradient = self.score_with_gradient(yy=yy, xx=xx)\n",
    "        return score\n",
    "        \n",
    "    def score_with_gradient(self, *, yy, xx):\n",
    "        \"\"\"\n",
    "        Return two values: the score G(`yy`,`xx`) and its gradient with respect to the params.\n",
    "        It's convenient to compute the gradient along with the score, and we'll need it later.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "  \n",
    "    def normalizer(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        The normalizing function `Z(xx)` or `Z(xx,oo)`, \n",
    "        often called the \"partition function\", that is used to define\n",
    "            p(yy | xx)     = \\frac{1}{Z(xx)}    exp G(...)\n",
    "            p(yy | xx, oo) = \\frac{1}{Z(xx,oo)} exp G(...)\n",
    "        \n",
    "        The default implementation computes this by a brute-force sum with `iterate_yy`,\n",
    "        but that could be overridden by a more efficient method when available.\n",
    "        (See formalisms.pdf, \"Marginal and conditional probabilities\".)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def prob(self, *, xx, oo=None, yy=None):\n",
    "        \"\"\"\n",
    "        Return p(yy | xx) or p(oo | xx).  Only one of `yy` or `oo` should be specified.\n",
    "        Computed using the scoring model G (the `model` attribute).\n",
    "        \n",
    "        If `yy` is not a legal string in the output space or `oo` is not a legal observable,\n",
    "        we would ideally raise an error, but you are not required to implement that.\n",
    "        \"\"\"\n",
    "        assert (oo is None) != (yy is None)\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def train_example(self, *, xx, oo=None, yy=None):  \n",
    "        \"\"\"\n",
    "        Improve our model parameters on a single example.\n",
    "        Either `yy` as a fully observed output or `oo` as a partial observation\n",
    "        should be specified, but not both. (See formalisms.pdf, \"Observations\".)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def sample(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        Return a sample `yy` from p(yy | xx) or p(yy | xx,oo)\n",
    "        There is a generic way to do this, \n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def train_epoch(self, dataset):\n",
    "        \"\"\"\n",
    "        Train for one epoch.\n",
    "        This means that we iterate once through `dataset`, passing \n",
    "        each example to `self.train_example`.\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for xx, oo, yy in dataset:\n",
    "            self.train_example(xx=xx, oo=oo, yy=yy)\n",
    "            count += 1\n",
    "            if count % 50 == 0: sys.stdout.write('\\rtrained on {} examples'.format(count))  # print progress\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DecisionAgent` controls *how* we make predictions once we have both our `TaskSetting` as `self.task` and `ProbabilityModel` as `self.model`.  We will experiment with a few different implementations of our decision rule below.\n",
    "<a id=\"DecisionAgent\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionAgent(object):\n",
    "    \"\"\"\n",
    "    Base class for the decision agents in this homework.\n",
    "    \n",
    "    To define a particular task setting, create a subclass\n",
    "    that specifies the space of outputs (`iterate_yy`),\n",
    "    the space of plans (`iterate_aa`, which defaults to\n",
    "    the space of outputs), and the reward function (`reward`).\n",
    "    \n",
    "    An instance of the subclass needs to also specify a particular \n",
    "    probability model (a `model` object) and a particular decision \n",
    "    rule (a `decision` function), which are passed as arguments \n",
    "    to the constructor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task, model):\n",
    "        \"\"\"Arguments to the constructor are a \"\"\"\n",
    "        super().__init__()\n",
    "        assert isinstance(task, TaskSetting)\n",
    "        assert isinstance(model, ProbabilityModel)\n",
    "        self.model = model\n",
    "        self.task = task\n",
    "    \n",
    "    def decision(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        Return some action `aa` that is appropriate to input `xx` and the partially\n",
    "        observed output `oo` (if any).  \n",
    "        \n",
    "        This might invoke `model`, `reward`, `iterate_aa`, and perhaps a random \n",
    "        number generator.\n",
    "        \n",
    "        This method will be replaced by the constructor.  It is included here\n",
    "        to document the calling convention, and also because a subclass might\n",
    "        define this method directly and override the constructor.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "            \n",
    "    def test(self, dataset):\n",
    "        \"\"\"\n",
    "        Run the predictor over `dataset` and return the average reward.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        count = 0\n",
    "        for xx, oo, yy in dataset:\n",
    "            aa = self.decision(xx=xx, oo=oo)\n",
    "            reward += self.task.reward(aa=aa, xx=xx, yy=yy)\n",
    "            count += 1\n",
    "            if count % 50 == 0: sys.stdout.write('\\revaluated {} examples'.format(count))\n",
    "        return reward / count\n",
    "    \n",
    "    def show_errors(self, dataset, count=20, reward_less_than=.75):\n",
    "        \"\"\"\n",
    "        Print out (up to) `count` examples in which the predictor got the \n",
    "        wrong answer.\n",
    "        \"\"\"\n",
    "        for xx, oo, yy in dataset:\n",
    "            aa = self.decision(xx=xx, oo=oo)\n",
    "            if self.task.reward(aa=aa, xx=xx, yy=yy) < reward_less_than:\n",
    "                print(\"yy: {yy}\\n\\taa: {aa}\\n\\txx: {xx}\\n\\too: {oo}\\n\".format(\n",
    "                    xx=''.join(xx),\n",
    "                    oo=''.join(oo),\n",
    "                    yy=''.join(yy),\n",
    "                    aa=''.join(aa)\n",
    "                ))\n",
    "                count -= 1\n",
    "                if count == 0: return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Problem_stresstask\"></a>\n",
    "Here we extend our [`TaskSetting`](#TaskSetting) class to define our environment of stressing vowels:  \n",
    "  * First fill in the function `iterate_y` to iterate through the domain of $\\mathbf{y}_t$ conditioned on the input $\\mathbf{x}, \\mathbf{o}$ and the prefix of the y string $\\mathbf{y}_{0:t-1}$ \n",
    "  * Then fill in `iterate_yy` to use `iterate_y` to iterate through the entire domain of $\\mathcal{Y}_{\\mathbf{x}, \\mathbf{o}}$.  Sometimes the parameter `oo` will be `None` indicating that we instead want to iterate the domain of $\\mathcal{Y}_\\mathbf{x}$\n",
    "  \n",
    "You can define an iterator in python using `yield` as follows:\n",
    "```python\n",
    "def f():\n",
    "    yield 'a'\n",
    "    yield 'e'\n",
    "for vowel in f():\n",
    "    print(vowel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StressTask(TaskSetting):\n",
    "    \"\"\"\n",
    "    Class of models for the vowel stress problem, with\n",
    "    a simple 0-1 reward function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        return 1 if yy == aa else 0    # was the answer exactly right?\n",
    "        \n",
    "    def iterate_y(self, *, xx, oo=None, yy_prefix):\n",
    "        \"\"\"\n",
    "        Iterate through the domain of yy_t given xx, oo, yy_{0:t-1}.\n",
    "        \"\"\"\n",
    "        t = len(yy_prefix)\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "   \n",
    "    def iterate_yy(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        Iterate through Y using self.iterate_y\n",
    "        \"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "    \n",
    "task = StressTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using that class, let's check that your `iterate_yy` correctly iterates over possible output strings given $\\mathbf{x}$ and optionally $\\mathbf{o}$.  We give you two test cases here to get started.  You should add your own test cases as well to this notebook cell.  \n",
    "\n",
    "(*Note*: Python uses `t = tuple(s)` and `s = ''.join(t)` to convert between a string `s` and a tuple `t` of its characters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(task.iterate_yy(xx=tuple('test'))) == {tuple('test'), tuple('tEst')}\n",
    "[''.join(yy) for yy in task.iterate_yy(xx=tuple('testphrase'), oo=tuple('t?stphrAs?'))]\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll now be able to create specific agents like this:\n",
    "```python\n",
    "mymodel = StressModel(task)\n",
    "myagent = StressAgent(task, model)\n",
    "```\n",
    "and then you can train that agent on data (by training its model object) and ask it for probabilities and decisions.  \n",
    "But wait - we don't yet have a `model` or a `decision` function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Problem_linearstressmodel\"></a>\n",
    "## Building a model for our agent\n",
    "\n",
    "For the first part of this assignment we will be using a simple linear scoring function $G_\\theta(\\mathbf{x}, \\mathbf{y})$ with hand written features.\n",
    "\n",
    "Our class `LinearStressModel` will define a linear scoring model $G$ for this task, with parameters $\\theta$.  \n",
    "Its `score` method can return a score $G_\\theta(\\mathbf{x},\\mathbf{y}) \\in \\mathbb{R} \\cup \\{ -\\infty \\}$.\n",
    "```python\n",
    "from math import inf \n",
    "model = LinearStressModel(task)\n",
    "assert model.score(xx=xx, yy=yy) == -inf\n",
    "```\n",
    "\n",
    "An instance of the class specifies a particular value for the parameters.  Its parameter vector $\\theta$ can be examined via the `params` property, and should be updated like this:\n",
    "```python\n",
    "update = np.zeros_like(model.params)  # a zero vector with the same dimensionality as params\n",
    "update[7] = 123                       # put some nonzero elements into that vector\n",
    "update[8] = 456\n",
    "model.params += update                # add it to params (+= makes Python invoke set_params)\n",
    "```\n",
    "This may seem a bit roundabout: why not just modify `params` directly via statements like `model.params[7] += 123`?  The reason is that the object does not actually have a `params` attribute.  Its parameters are stored in one or more attributes with other names.  Calling `params` invokes a \"getter\" function (the `params` property) that constructs a new vector of all those parameters.  Modifying that new vector would not change the original parameters, whereas calling `params += ...` invokes a \"setter\" function that does so.\n",
    "\n",
    "Note that `LinearStressModel` is a *particular* linear scoring model, but it could be subclassed to include more features other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearStressModel(ProbabilityModel):   # would have been nicer to inherit from a Model base class\n",
    "\n",
    "    def __init__(self, task):\n",
    "        super().__init__(task)\n",
    "        self.initialize_params()\n",
    "\n",
    "    def initialize_params(self):\n",
    "        np.random.seed(42)\n",
    "        self._theta = np.array([\n",
    "            .1,\n",
    "            .05,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "        ])\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        return np.array(self._theta)\n",
    "\n",
    "    @params.setter\n",
    "    def params(self, val):\n",
    "        assert np.isfinite(val).all()\n",
    "        self._theta[:] = val\n",
    "\n",
    "    def features(self, *, xx, yy):\n",
    "        \"\"\"Extract a feature vector that measures various features of the pair (xx,yy).\"\"\"\n",
    "\n",
    "        string = ''.join(yy)                          # concatenate symbols into an ordinary python string\n",
    "        vowels = re.sub(r'[^aeiouAEIOU]','', string)  # extract just the vowels\n",
    "        \n",
    "        # All of our features are counts of structures in `(xx,yy)`.\n",
    "        # For this problem, the features don't need to look at `xx`, but features for a POS tagger would do that.\n",
    "        uppercase_vowels = len(re.findall(r'[AEIOU]', vowels))\n",
    "        altcase_vowels = len(re.findall(r'(?=([aeiou][AEIOU])|([AEIOU][aeiou]))', vowels))\n",
    "        enduppercase_vowels = len(re.findall(r'[AEIOU]$', vowels))\n",
    "        uppercase_consonants = len(re.findall(r'[TNSRHDLC]', string))  \n",
    "        length = len(string)\n",
    "\n",
    "        # Assemble those counts into a feature vector.\n",
    "        return np.array([uppercase_vowels,\n",
    "                         altcase_vowels,\n",
    "                         enduppercase_vowels,\n",
    "                         uppercase_consonants,\n",
    "                         length])\n",
    "\n",
    "    def score_with_gradient(self, *, xx, yy):\n",
    "        \"\"\"\n",
    "        Return two values: the score G(`xx`,`yy`) and its gradient with respect to the params.\n",
    "        It's convenient to compute the gradient along with the score, and we'll need it later.\n",
    "        \"\"\"\n",
    "        # The score is the dot product of params theta with the feature vector,\n",
    "        # which implies that its gradient is just the feature vector.\n",
    "        f = self.features(xx=xx, yy=yy)\n",
    "        score = self._theta.dot(f)    \n",
    "        return float(score), f\n",
    "    \n",
    "    def normalizer(self, *, xx, oo=None):\n",
    "        \"\"\"The normalizing function Z(xx) or Z(xx, oo)\"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def prob(self, *, xx, oo=None, yy=None):\n",
    "        \"\"\"The probability: P(y | x) or P(o | x)\"\"\"\n",
    "        assert (oo is None) != (yy is None)\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    \n",
    "linear_model = LinearStressModel(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model out with its default initial parameter setting.  \n",
    "What is each feature doing in the cell below?\n",
    "\n",
    "**Answer:** <span style='color:red'>FILL IN</span>\n",
    "\n",
    "Why don't the fourth and fifth features help to discriminate among the `yy` candidates?  Will that be true for every `xx`, or just for `testphrase`?\n",
    "\n",
    "**Answer:** <span style='color:red'>FILL IN</span>\n",
    "\n",
    "To understand the features, it will probably help to experiment, so you may want to add your own examples to the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testphrase = tuple('testphrase')\n",
    "[( ''.join(yy),                                   # string yy\n",
    "   linear_model.features(xx=testphrase, yy=yy),   # yy's feature vector with this xx\n",
    "   linear_model.score(xx=testphrase, yy=yy)  )    # yy's score with this xx, using the current parameters \n",
    " for yy in task.iterate_yy(xx=testphrase)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go back to the [cell above](#Problem_linearstressmodel) and fill in the `normalizer` and `prob` methods.\n",
    "\n",
    "Let's check your implementation.  \n",
    "Using the scores above, give simple numerical expressions (which may refer to $Z$) for:\n",
    "\n",
    "$p(\\mathbf{Y}=\\texttt{testphrAsE} \\mid \\mathbf{X}=\\texttt{testphrase}) =$ <b><span style='color:red'>FILL IN</span></b>\n",
    "\n",
    "$p(\\mathbf{Y} \\in \\texttt{testphrAs?} \\mid \\mathbf{X}=\\texttt{testphrase}) =$ <b><span style='color:red'>FILL IN</span></b>\n",
    "\n",
    "where $\\texttt{testphrAs?}$ is being informally used to mean the *set* of output strings compatible with that partial observation.  \n",
    "Those numerical expressions should match the answers computed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linear_model.normalizer(xx=testphrase)\n",
    "from math import isclose\n",
    "assert isclose(Z, 9.812839692144227)  # checks that you got the right value\n",
    "\n",
    "[Z, \n",
    " linear_model.prob(xx='testphrase',yy='testphrAsE'),\n",
    " linear_model.prob(xx='testphrase',oo='testphrAsE'),  # should be the same as previous line\n",
    " linear_model.prob(xx='testphrase',oo='testphrAs?')]  # should be bigger than previous line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our agent needs a decision rule.  Define a \"Viterbi\" decision rule that chooses the *most probable* `yy` (which is also the one that scores highest):\n",
    "$$\\text{argmax}_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}}} G_\\theta(x, y)$$\n",
    "\n",
    "If `oo` is specified, the rule should choose the most probable `yy` that is *compatible* with `oo`:\n",
    "$$\\text{argmax}_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x},\\mathbf{o}}} G_\\theta(x, y)$$\n",
    "\n",
    "Our DecisionAgent defines `self.task` with all methods defined [above](#DecisionAgent) such as `self.task.iterate_yy` and our LinearStressModel with `self.model` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViterbiAgent(DecisionAgent):\n",
    "\n",
    "    def decision(self, *, xx, oo=None):\n",
    "        \"\"\"viterbi decision rule\"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "viterbi_agent = ViterbiAgent(task, linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `viterbi_agent` is behaving as you expect, by trying out some more test cases in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_agent.decision(xx='testphrase')\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what kind of predictions the agent makes on *development* data.  \n",
    "(We haven't trained its parameters yet.)\n",
    "\n",
    "Fill in assignments to `aa` (the prediction) and `reward` (the reward received as a result), so that the code prints out tuples $(R, \\mathbf{x}, \\mathbf{o}, \\mathbf{y}, \\mathbf{a})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, oo, yy in iterate_data('dev', max_examples=5):\n",
    "    aa = reward = None  # replace with actual computation below\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    print((reward,\n",
    "           ''.join(xx),\n",
    "           ''.join(oo) if oo is not None else None,\n",
    "           ''.join(yy) if yy is not None else None,\n",
    "           ''.join(aa)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the development dataset to check the overall quality of our predictions.\n",
    "This returns the *average reward* over all development examples (so higher values are better).\n",
    "Since we defined reward to be 1 if `aa==yy` and 0 otherwise, our average reward is the fraction of examples where the agent predicted `yy` exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our \"success\" probably came from the fact that the dev data included partial observations $\\mathbf{o}$ of the output $\\mathbf{y}$, so the agent only had to pick the output from the set $\\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}, \\mathbf{o}}$ of outputs that are compatible with $\\mathbf{o}$.\n",
    "\n",
    "How much worse would we have done without $\\mathbf{o}$, so that we have to pick the right output from the larger  set $\\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over versions of the examples for which oo is replaced by None\n",
    "viterbi_agent.test([(xx,None,yy) for (xx,oo,yy) in iterate_data('dev')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We will define our training objective as $A_{y \\mid x}(\\boldsymbol\\theta) = \\sum_{n=1}^N \\log p_\\boldsymbol\\theta(\\mathbf{y}_n \\mid \\mathbf{x}_n) - c || \\boldsymbol\\theta ||^2$ where we will maximize the log probability of our model and regularize our parameter vector $\\theta$ using L2.  We will take a one step stochastic gradient descent per each sample in our training set.\n",
    "\n",
    "We can also train the case that we have a partial observation $\\mathbf{o}_n, \\mathbf{x}_n$.  In this case we will be maximizing the log probability of the expression $P(\\mathbf{o}_n \\mid \\mathbf{x}_n)$ using $P(\\mathbf{o} \\mid \\mathbf{x}) = \\sum_{\\mathbf{y} \\in \\mathcal{Y}_{x,o}} P(\\mathbf{y} \\mid \\mathbf{x})$.\n",
    "\n",
    "\n",
    "To compute the update for this rule, we need to derive the gradient for $\\nabla_\\theta A(\\theta)$.\n",
    "\n",
    "Here is the computation for $\\nabla_\\theta A_{y \\mid x}(\\theta)$, you will have to derive for the $\\nabla_\\theta A_{o \\mid x}(\\theta)$ below.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A_{y \\mid x}(\\boldsymbol\\theta) &= \\sum_{n=1}^N \\log p_\\boldsymbol\\theta(\\mathbf{y}_n | \\mathbf{x}_n) - c || \\boldsymbol\\theta||^2 \\\\\n",
    "&= \\log \\frac{\\exp({G_\\boldsymbol\\theta(\\mathbf{y}_n | \\mathbf{x}_n)})}{Z_\\theta(x)} - c || \\boldsymbol\\theta||^2 \\\\\n",
    "&= G_\\boldsymbol\\theta(\\mathbf{y}_n | \\mathbf{x}_n) - \\log Z_\\theta(x) - ||\\boldsymbol\\theta|| ^2\n",
    "\\end{align*}\n",
    "$$\n",
    "Substituting $Z_\\boldsymbol\\theta(x) = \\sum_{y \\in Y_x} \\exp({G_\\boldsymbol\\theta(\\mathbf y_n \\mid \\mathbf x_n)})$, we get:\n",
    "$$\n",
    "\\begin{align*}\n",
    "&= G_\\boldsymbol\\theta(\\mathbf{y}_n | \\mathbf{x}) - \\log \\sum_{y \\in Y} \\exp({G_\\boldsymbol\\theta(\\mathbf y_n | \\mathbf x_n)}) - ||\\boldsymbol\\theta|| ^2 \\\\\n",
    "\\nabla_\\theta A_y(\\boldsymbol\\theta) &= \\nabla_\\boldsymbol\\theta G(\\mathbf x \\mid \\mathbf y) - \\frac{1}{Z_\\boldsymbol\\theta(x)} \\sum_{\\mathbf{y} \\in \\mathbf{Y}} \\exp(G_\\boldsymbol\\theta(\\mathbf y_n \\mid \\mathbf x_n)) \\nabla_\\boldsymbol\\theta G_\\boldsymbol\\theta(\\mathbf y_n \\mid \\mathbf x_n) - \\frac{c}{2} * \\boldsymbol \\theta\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out the expression for $A_{o \\mid x}(\\boldsymbol\\theta)$.  Hint: $\\mathbf{o}$ should **not** appear in the denominator or *free* expression.  You may find Jason's [tutorial](https://www.cs.jhu.edu/~jason/tutorials/loglin/formulas.pdf) on log linear models helpful\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A_{o \\mid x}(\\boldsymbol\\theta) &= \\color{red}{\\text{FILL IN}} \\\\\n",
    "\\nabla_\\theta A_{o \\mid x}(\\boldsymbol\\theta) &= \\color{red}{\\text{FILL IN}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To *maximize* the objective function using stochastic gradient accent our update rule is\n",
    "$$\\boldsymbol\\theta \\mathrel{+}= \\alpha * \\nabla_\\boldsymbol\\theta A(\\boldsymbol\\theta)$$\n",
    "Where $\\boldsymbol\\theta$ is our parameter vector (`self.params`), $\\nabla_\\boldsymbol\\theta A(\\boldsymbol\\theta)$ is a vector of gradients that we computed above and $\\alpha$ is a scalar representing our learning rate.\n",
    "\n",
    "In the above equations, $G_\\theta$ is still the scalar from our score function and $\\nabla_\\boldsymbol\\theta G$ refers to the gradient vector return by `score_with_gradient` on our [ProbabilityModel](#ProbabilityModel).  (`G, gradient_G = score_with_gradient(...)`)\n",
    "\n",
    "The parameters of the score function can be updated with `self.params += update_vector` as discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableLinearStressModel(LinearStressModel):\n",
    "\n",
    "    # Use this for your learning rate\n",
    "    alpha = .05\n",
    "    \n",
    "    # Use this for your L2 regularization\n",
    "    c = .001\n",
    "    \n",
    "    def compute_gradient(self, *, xx, yy):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "    \n",
    "    def train_example(self, *, xx, oo=None, yy=None):\n",
    "        assert (yy is None) != (oo is None)  # check that we have yy or oo\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "    \n",
    "\n",
    "trainable_linear_model = TrainableLinearStressModel(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the log-linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre training reward\n",
    "trainable_linear_model.initialize_params()\n",
    "viterbi_agent = ViterbiAgent(task, trainable_linear_model)\n",
    "viterbi_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    trainable_linear_model.train_epoch(iterate_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how well the model works now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the parameters that the model learns, which features does the model learn are the most important for doing well on this task?\n",
    "\n",
    "<b><span style='color:red'>FILL IN</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_agent.model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A new reward function\n",
    "\n",
    "So far we have been using a reward function which only rewards us when we are *exactly* right, however there are some scenarios where we might be able to receive a fractional reward in the case that we have most of the output correct.\n",
    "\n",
    "Below we define a simple reward function which compares the hamming distance between two strings.\n",
    "This function also defines an asymmetric reward in the case that we predict incorrectly. It is better to predict a lowercase letter rather than a capital one as we can receive a negative reward of -.3 for any lower case vowel rather than -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HammingTask(StressTask):\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        return sum(0 if aa[t] == yy[t] else (-.3 if aa[t] in 'aeiou' else -1.0) for t in range(len(aa))) / len(aa)\n",
    "\n",
    "hamming_task = HammingTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_task.reward(aa='tEst', xx='test', yy='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_task.reward(aa='test', xx='test', yy='tEst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward-infused decoding\n",
    "\n",
    "Our old decision rule -- the Viterbi decoder -- tries to maximize the old reward (0 or 1).\n",
    "Let's change the decision rule to try to optimize its prediction for the new (arbitrary) reward function instead.\n",
    "This is minimum Bayes risk (MBR) decoding, although since we've formulated the problem as maximizing expected reward rather than minimizing expected loss, we should really call it maximum Bayes value.\n",
    " $$ \\mathrm{argmax}_{\\mathbf{a} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}}} \\sum_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x},\\mathbf{o}}} P(\\mathbf{y} \\mid \\mathbf{x}, \\mathbf{o}) \\cdot R(\\mathbf{a} \\mid \\mathbf{x},\\mathbf{y}) $$\n",
    "\n",
    "where $p(\\mathbf{y} \\mid \\mathbf{x}, \\mathbf{o}) = \\frac{1}{Z(\\mathbf{x}, \\mathbf{o})} \\exp G_\\boldsymbol\\theta(\\mathbf{x}, \\mathbf{y})$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumBayesValueAgent(DecisionAgent):\n",
    "    \n",
    "    def decision(self, *, xx, oo):\n",
    "        ### STUDENTS START\n",
    "        ### Bayes min risk decoding\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "    \n",
    "max_bayes_value = MaximumBayesValueAgent(hamming_task, trainable_linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test how well Bayes min risk performs with our Hamming distance reward.\n",
    "\n",
    "Note: We are able to use the `trainable_linear_model` from before *without* retraining the model.  Our learned function defines $G_\\boldsymbol\\theta$ which defines our probability model over possible true underlying states $p(y \\mid x, o)$ but we are trying to maximize our reward given our belief about which state $\\mathbf{y}$ we are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bayes_value.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *\"Crazy\"* reward function\n",
    "  \n",
    "Our environment can define any reward function it wants which compares our generated value $\\mathbf{a}$ and the known gold answer $\\mathbf{y}$. One of the most common reward functions used in Natural Language Processing is BLEU.  BLEU is primarily used in machine translation. It compares the number of overlapping n-grams between the generated sequence $\\mathbf{a}$ and the gold sequence $\\mathbf{y}$.  Additionally, it contains a brevity penalty and can work when $\\mathbf a$ and $\\mathbf y$ are different lengths. This reward function has become popular for scoring machine translation systems as it has been shown to correlate with human preferences for translations, can be easily computed and it allows us to compare between two translations when neither is exactly correct.\n",
    "\n",
    "In this homework, we will be implementing a slightly simplified version of BLEU in that for smoothing we are just going to use $\\epsilon$ as defined below.  BLEU operates by computing the harmonic mean of the precision between n-grams of length $\\{1,2,3,4\\}$.  By smoothing our objective we will still recover information about our shorter n-grams even in the case that we fail to match any of the longer n-grams.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\#x_c &:= \\text{Number of instances of ngram $c$ inside string $x$} \\\\\n",
    "  \\text{ngram}_n &:= \\text{set of ngrams $n$ tokens long} \\\\\n",
    "  \\epsilon &:= .01 \\\\\n",
    "  p_n &= \\frac{\\max\\{\\sum_{c \\in \\text{ngram}_n} \\min\\{\\#\\text{pred}_{c}, \\#\\text{gold}_{c}\\}, \\epsilon \\} }{\\max\\left\\{\\sum_{c \\in \\text{ngram}_n} \\#\\text{gold}_c, 1\\right\\}} & \\textit{Precision with ``smoothing''} \\\\\n",
    "  \\textit{bp}(c, r) &= \\left\\{ \\begin{array}{cc} 1 & c \\ge r \\\\ e^{1 - r/c} & \\text{otherwise} \\end{array} \\right. & \\textit{brevity penalty} \\\\\n",
    "  \\textit{bleu}(\\text{pred}, \\text{gold}) &:= \\text{exp}\\left( \\frac{1}{4} \\sum_{i\\in[1, 4]} \\log(p_i) \\right) * \\textit{bp}(\\text{len}(\\text{pred}), \\text{len}(\\text{gold}))\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENTS START\n",
    "### Helper functions for bleu\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "def bleu(*, aa, yy):\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    \n",
    "\n",
    "class BleuStressTask(StressTask):\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        return bleu(aa=aa, yy=yy)\n",
    "    \n",
    "bleu_task = BleuStressTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check our BLEU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bleu(aa='test', yy='test') == 1\n",
    "assert np.isclose(bleu(aa='TEST', yy='test'), .0045180100180492264)\n",
    "\n",
    "### STUDENTS START\n",
    "### Write additional tests for your bleu function\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how we are doing with BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_max_bayes_value = MaximumBayesValueAgent(bleu_task, trainable_linear_model)\n",
    "\n",
    "bleu_max_bayes_value.test(iterate_data('dev', max_examples=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up the BLEU Implementation\n",
    "\n",
    "It now appears that our test method has become somewhat slow after introducing the BLEU function.  When building more complicated models, we will often have to put our engineering hats on and figure out how to make our programs run faster.\n",
    "\n",
    "First lets get a baseline for how fast our BLEU decoder is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time bleu_max_bayes_value.test(iterate_data('dev', max_examples=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and identify the slow functions using [`%prun`](http://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-prun).  This will generate a profile of all the functions that are called when running and how long each function takes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun bleu_max_bayes_value.test(iterate_data('dev', max_examples=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have identified which functions are *slow* we are going to use [Cython](https://cython.readthedocs.io/en/latest/) to make our program faster by compiling the slow functions.\n",
    "\n",
    "Cython uses python like syntax but adds a few additional annotations which allows cython to better compile a faster function.\n",
    "     \n",
    "#### Short Cython tutorial / hints\n",
    " 1. In our jupyter notebook, we can load cython using `%load_ext cython`  we can then use cython inside of any jupyter cell by putting `%%cython` at the top of the cell.  \n",
    " 2. The parameter `%%cython -a` will turn on verbose mode which is helpful when trying to debug why our function is slow.  This will show the resulting C program that is generated from our cython code.  Lines that are highlighted in <span style='background-color:yellow'>yellow</span> indicate that they are invoking a lot of python internals, and thus will be *generally slower*\n",
    " 3. Adding types to parameters can help reduce the overhead of calling a function.  Try both of these expressions in a `%%cython -a` block\n",
    " ```cython\n",
    "%cython -a\n",
    " def multiply_by_2(a):\n",
    "      return a * 2\n",
    " cdef float multiply_by_2(float a):\n",
    "      return a * 2\n",
    " ```\n",
    " 4. Defining types on local variables can also help, some types you could use include: `dict`, `int`, `float`.  Defining a range parameter as `int` will help cython generate a C style for loop.  Using `dict` lets cython omit some extra checks when accessing the elements inside of a dictionary type\n",
    " ```cython\n",
    "%cython -a\n",
    " cdef foo():\n",
    "      cdef int i\n",
    "      cdef dict d = {}\n",
    "      for i  in range(10):\n",
    "           d[i] = i\n",
    " ```\n",
    " 5. We can replace `np.exp` with `libc.math.exp` which will use the `exp` function defined in C's `math.h` instead of making a slower call to numpy.\n",
    " \n",
    "\n",
    "There is no *correct* answer to how fast your program should run.  You need to decide when your program is fast enough such that you can actually study the problems that you are interested in.  For this problem set, you should aim to get at least 2-3x faster that your baseline BLEU implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "from libc.math cimport exp, log\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "### STUDENTS START\n",
    "### Helper functions for bleu\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "def faster_bleu(tuple yy, tuple aa):\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that our new BLEU function is predicting the same as our old function.  Also define a few additional checks of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bleu(yy=tuple('tEst'), aa=tuple('test')) == faster_bleu(yy=tuple('tEst'), aa=tuple('test'))\n",
    "\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how much faster the fast bleu function is compared to the baseline bleu function\n",
    "\n",
    "  1. Baseline BLEU function runtime: <b><span style='color:red'>FILL IN</span> seconds</b>\n",
    "  2. Faster BLEU function runtime: <b><span style='color:red'>FILL IN</span> seconds</b>\n",
    "  3. Performance improvement (faster/baseline): <b><span style='color:red'>FILL IN</span> %</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterBleuStressTask(StressTask):\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        return faster_bleu(aa=aa, yy=yy)\n",
    "    \n",
    "faster_bleu_task = FasterBleuStressTask()\n",
    "\n",
    "faster_bleu_max_bayes_value = MaximumBayesValueAgent(faster_bleu_task, trainable_linear_model)\n",
    "%time faster_bleu_max_bayes_value.test(iterate_data('dev', max_examples=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that our BLEU function is much faster, we can run it over the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_bleu_max_bayes_value.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from $p(\\mathbf{y} \\mid \\mathbf{x})$\n",
    "\n",
    "So far, our decision method has only been returning the *best* sample, and we have accomplished this by enumerating the entire domain of $\\mathcal{Y}$.  However, it is often intractable to enumerate $\\mathcal{Y}$, so we will instead sample a good $\\mathbf y$.  \n",
    "\n",
    "First we are just going to enumerate our entire domain of $\\mathbf{Y}$ and compute the probability of all values $y$ as a baseline brute force sampling method.  You might find [np.random.choice](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.choice.html) useful to draw a sample from this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruteForceSampler(TrainableLinearStressModel):\n",
    "    \n",
    "    def sample(self, *, xx, oo=None):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "\n",
    "brute_force_sampler = BruteForceSampler(task)\n",
    "brute_force_sampler.initialize_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your sampler.  You should see some variations in predicted outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, oo, yy = next(iterate_data())\n",
    "for i in range(20): print(brute_force_sampler.sample(xx=xx, oo=oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumerating the entire domain of $\\mathcal{Y}$ can be slow, so now we are going to replace our brute force sampler with a Gibbs sampler.\n",
    "\n",
    "The pseudo code for a Gibbs sampler looks like this:\n",
    "  * $\\mathbf{y}$ = initial start string\n",
    "  * Repeat for $\\mathbf{n}$ iterations:\n",
    "    * Randomly choose a position $j$ such that (? in $\\mathbf{o}$)\n",
    "      * $y[j]$ = capital\n",
    "      * $p_{\\text{capital}} = \\tilde{P}(y | x, o)$\n",
    "      * $y[l]$ = lower case\n",
    "      * $p_\\text{lower} = \\tilde{P}(y | x, o)$\n",
    "      * make y[l] capital with probability $\\frac{p_\\text{capital}}{p_\\text{lower} + p_\\text{capital}}$\n",
    "  * return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GibbsSampler(TrainableLinearStressModel):\n",
    "    \n",
    "    def sample(self, *, xx, oo=None):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "\n",
    "        \n",
    "gibbs_sampler = GibbsSampler(task)\n",
    "gibbs_sampler.initialize_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Gibbs sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, oo, yy = next(iterate_data())\n",
    "for i in range(20): print(gibbs_sampler.sample(xx=xx, oo=oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that our two sampling methods are generating samples from the same distribution, we are going to compute the Kullback-Leibler divergence.  The KL divergence computes the difference in the expected probability between our two distributions $P$ and $Q$.  Observe that the expression $\\log \\frac{P(y)}{Q(y)}$ will be zero in the case that both $P$ and $Q$ give the same probability to a value $\\mathbf y$.\n",
    "\n",
    "$$\\text{KL}(P \\mid\\mid Q) = \\sum_{\\mathbf{y} \\in \\mathbf{Y}} P(\\mathbf y) \\log \\frac{P(\\mathbf y)}{Q(\\mathbf y)}$$\n",
    "\n",
    "We will approximate $P(\\mathbf y)$ and $Q(\\mathbf y)$ by generating 5000 samples from our two sampling methods and counting the number of times that $\\mathbf y$ was generated.\n",
    "\n",
    "You should get a value $< .1$ if both of your sampling methods are working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl(method_1, method_2):\n",
    "    xx, oo, yy = next(iterate_data())\n",
    "    n = 5000\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "compute_kl(brute_force_sampler, gibbs_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use our samplers to generate a few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplingAgent(DecisionAgent):\n",
    "    \n",
    "    def decision(self, *, xx, oo=None):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "agent_brute = SamplingAgent(task, brute_force_sampler)\n",
    "agent_gibbs = SamplingAgent(task, gibbs_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First using the untrained linear classifier for our tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_brute.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_gibbs.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train and retest our samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier of our samplers\n",
    "# for i in range(2):\n",
    "#     brute_force_sampler.train_epoch(iterate_data())\n",
    "# for i in range(2):\n",
    "#     gibbs_sampler.train_epoch(iterate_data())\n",
    "\n",
    "# Question: why can we replace the above lines and avoid retraining by\n",
    "# copying the parameters from our already trained model\n",
    "brute_force_sampler.params = trainable_linear_model.params\n",
    "gibbs_sampler.params = trainable_linear_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_brute.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_gibbs.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The final test!\n",
    "\n",
    "Throughout this homework we have implemented a number of different models, and we have been tuning, debugging and developing these models using our *development* set.  Now that we have reached the end, choose **one** of your models, decision rules, and tasks to run on the testing data and report this number.\n",
    "\n",
    "Performance on the testing dataset: <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENTS START\n",
    "### my_chosen_task = ????\n",
    "### my_chosen_model = ????\n",
    "### my_chosen_agent = ????\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "my_chosen_agent.test(iterate_data('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}