{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "456016b4-9f60-4e85-afd8-d4483f103580",
    "deletable": false
   },
   "source": [
    "# Homework 1 - Slow general algorithms for sequence labeling\n",
    "\n",
    "For homework 1, we will mainly be looking at a contrived task described below.  In this first homework, you will use slow but general algorithms.  They could be applied to *any* finite sequence problem, since they do not take advantage of any special problem structure.\n",
    "\n",
    "The coding problems in this assignment are designed to be fairly small, with each taking around **5-20 lines of code**.  Throughout this assignment you will see parameters `xx`, `yy`, `oo`, `aa`, which correspond to  $\\mathbf{x},\n",
    "\\mathbf{y}, \\mathbf{o}, \\mathbf{a}$ from [the formalisms document](https://seq2class.github.io/scribe-notes/formalisms.pdf): the doubled letter is meant to suggest that the variable represents a string.  So `xx` is the input string, `yy` ranges over possible output strings, `oo` is a (partial) observation of the output string, and `aa` ranges over over possible decisions (predictions or other plans) that our system can choose.\n",
    "\n",
    "There's an awful lot of code here to read!  But this is getting you set for future assignments, where we will make gradual extensions to this codebase.  Understanding the class design will also reinforce your understanding of the concepts in the formalisms document.  Finally, you might learn something here about Python and object-oriented design.\n",
    "\n",
    "## Our applied task\n",
    "\n",
    "For this assignment we are predicting which vowels in a word are stressed.\n",
    "In the (made-up) natural language used in our dataset, every vowel sound is \n",
    "represented by one of the letters `aeiou`, and we will use `AEIOU`\n",
    "to indicate their stressed versions.\n",
    "\n",
    "Following the notation defined so far, the input sequence $\\mathbf{x}$ is our input\n",
    "word (with no capitalization).  Each possible output $\\mathbf{y}$ \n",
    "contains the same sequence of letters as $\\mathbf{x}$, but with some of them \n",
    "`cApitalIzed` to indicate stress.  Therefore, if $\\mathbf{x}$ contains $m$ vowels, \n",
    "then $|\\mathcal{Y}_{\\mathbf{x}}| = 2^m$.  \n",
    "\n",
    "Sometimes this exponentially large search space gets reduced because for *some* vowels, \n",
    "we *observe* whether they are stressed or unstressed.  The observation is a string \n",
    "$\\mathbf{o}$ that is a version of $\\mathbf{y}$ with some of the vowels already given correctly \n",
    "as capital or lowercase, but unobserved vowels replaced with `?`.  So if \n",
    "$\\mathbf{o}$ contains $n$ question marks (where $0 \\leq n \\leq m$), \n",
    "then $|\\mathcal{Y}_{\\mathbf{x,o}}| = 2^n$.\n",
    "\n",
    "### Sample inputs and outputs\n",
    "| $\\mathbf{x}$ | $\\mathbf{o}$ | $\\mathbf{y} \\in \\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}$ | $\\mathbf{y} \\notin \\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}$ (illegal)|\n",
    "|:-------------:|:------------:|:---------------------:|:--------------------|\n",
    "| `helilela` | `h?lil?l?` | `helilela` | `Helilela` |\n",
    "| | | `helilelA` | `helIlela` |\n",
    "| | | `hElilelA` | ... |\n",
    "| | |    ...     |     |\n",
    "| `idonotul` | `?don?t?l` | `IdonotUl` | `idOnotUl` |\n",
    "| | | ... | ... |\n",
    "\n",
    "## Assignment Instructions\n",
    "\n",
    "Follow through the assignment in order.  Each text cell will provide details about the task and explain what is expected.\n",
    "\n",
    "### Code\n",
    "\n",
    "Inside of code blocks, you will see `### STUDENTS START` to indicate where you are expected to edit the cell and fill in some code (until `### STUDENTS END`).\n",
    "Do NOT create new cells to insert code -- these will not be registered by the autograder!\n",
    "\n",
    "### Writing\n",
    "\n",
    "There are also a few short-answer questions throughout the assignment.\n",
    "These are marked in red with <span style='color:red'>FILL IN</span>; again, edit the cell and only this cell to give your answer.\n",
    "\n",
    "You can search for the phrases `STUDENTS START` and `FILL IN` to see if you have any unfinished work.  You will hand this notebook in via Gradescope -- more details on this will be posted on Piazza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "e2153889-c7ff-43c4-aa70-b8080837bd07",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from collections import namedtuple\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "Data_type = namedtuple('Data', ['xx', 'oo', 'yy'])\n",
    "\n",
    "def iterate_data(filename='train', *, max_examples=None):\n",
    "    file = open(filename+'.tsv')\n",
    "    for n, row in enumerate(csv.DictReader(file, delimiter='\\t')):\n",
    "        if max_examples is not None and n >= max_examples:\n",
    "            break\n",
    "        yield Data_type(\n",
    "            xx=tuple(row['xx']),\n",
    "            oo=tuple(row['oo']) if 'oo' in row else None,\n",
    "            yy=tuple(row['yy']) if 'yy' in row else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "de175fbf-3ad0-4707-a475-4a7d25635873",
    "deletable": false
   },
   "source": [
    "## Let's start by looking at the data ...\n",
    "\n",
    "Our *strings* are sequences of symbols from our alphabet, represented as Python tuples.  Although our symbols in this problem are letters, they might be words in future problems, which is why we \"convert\" them into Python tuples of characters (python's duck typing makes it all still work out if you don't though (as you can still access the n-th character the same way) -- and it's sometimes less visual clutter -- so sometimes we omitted the `tuple()` call).\n",
    "\n",
    "Each example consists of a triple `(xx,oo,yy)` where the observation string `oo` may include the special symbol `?`.\n",
    "* A **training example** may specify either \n",
    "  * `oo=None` and `yy` is the fully observed output\n",
    "  * `yy=None` and `oo` is a partial observation of the output (see formalisms.pdf, \"Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "g.cell_uuid": "a86c5260-5441-4a9f-ba69-e520cc6e8121",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "itr = iterate_data()   # uses training set by default\n",
    "print(next(itr))       # look at the first example in our training set\n",
    "next(itr)              # look at the second example in our training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "a9095c9e-129d-4f64-a544-bccbdf11d31d",
    "deletable": false
   },
   "source": [
    "* A **test example** consists of a triple `(xx,oo,yy)`, where `yy` is the correct answer.\n",
    "  The prediction rule will be given `(xx,oo)` and asked to predict `yy`.\n",
    "  * Usually `oo=None`, so the rule must simply predict `yy` from `xx`.  \n",
    "  * However, if `oo` is specified, this informs the predictor that the true `yy` is compatible with `oo`.  This extra information should improve the prediction.\n",
    "  <br><br>\n",
    "* A **dev example** has the same format as a test example, since the development set is a test set that you use for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "7ae4676d-73f7-4e4a-9a50-24ac8fb36b09",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "itr = iterate_data('dev')   # okay to peek at the development dataset (but not the real test data!)\n",
    "print(next(itr))            # oo as partially observed output\n",
    "next(itr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "70d7a8f8-e6ac-4e7f-ac3c-24eb3028540f",
    "deletable": false
   },
   "source": [
    "## Task settings\n",
    "\n",
    "Here is the base interface that we will be extending for the remainder of this homework.\n",
    "All of our methods are defined with a `*` argument, like this:\n",
    "```python\n",
    "def mymethod(self, *, xx, oo=None, yy):\n",
    "    pass   \n",
    "```\n",
    "The `,*,` prevents the parameters `xx, oo, yy` from being passed as positional arguments; instead they must be passed as keyword arguments.  This makes the code easier to read, and prevents errors due to accidentally specifying the arguments in the wrong order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "829b8038-ef9a-47c4-962a-6fa9bfbfc51d",
    "deletable": false
   },
   "source": [
    "A `TaskSetting` object defines the setup for our decision or prediction task.  Its `iterate_yy` method defines the output spaces $\\mathcal{Y}_{\\mathbf{x}}$ and $\\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}$, while its `iterate_aa` method defines the action space $\\mathcal{A}_\\mathbf{x}$.  Its `reward` method defines the the environment's reward function $R(\\mathbf{a} \\mid \\mathbf{x}, \\mathbf{y})$ that returns how good our prediction $a$ was given the true answer is $y$.  For now, just read the code; we will start implementing the methods on this class in the [first problem](#Problem_stresstask).\n",
    "<a id=\"TaskSetting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "54a72121-29ed-473f-a4c0-3382005539f7",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class TaskSetting(object):\n",
    "    \"\"\"\n",
    "    Base interface for specifying a task.\n",
    "    Defines the output space, the action space, and the reward function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def iterate_yy(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        Returns an iterator over legal `yy` sequences (represented as tuples).\n",
    "        If an observation `oo` is specified, restricts to `yy` sequences that \n",
    "        are consistent with `oo`.\n",
    "        This method *defines* the space of output strings that we will consider \n",
    "        (although some of those could turn out to have probability 0).\n",
    "        It also *defines* how `oo` is to be interpreted.\n",
    "        The default implementation generates each `yy` one character at a time,\n",
    "        by calling `iterate_y`.\n",
    "        \n",
    "        Caveat to users: Some implementations (for efficiency), instead of yielding\n",
    "        a stream of immutable tuples, might keep yielding mutated versions of \n",
    "        the *same* list object.  Thus, you should print, analyze,\n",
    "        or copy the `yy` values as you iterate through them.  Don't write `list(iterator)` \n",
    "        since that might give a list of many pointers to the *same* object; to save all\n",
    "        values in a list, you should instead write `[tuple() for yy in iterator]`.\n",
    "        \"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def iterate_y(self, *, xx, oo=None, yy_prefix):\n",
    "        \"\"\"\n",
    "        Returns an iterator over legal next characters of `yy`.\n",
    "        In other words, returns all characters `y` such that\n",
    "        the concatenation `y_prefix + y` is a prefix of some\n",
    "        output `yy` that is legal given input string `xx` \n",
    "        and observable `oo`.\n",
    "        (This set of characters is discussed in formalisms.pdf, \n",
    "        \"Restricting summations to the output space\".)\n",
    "        \n",
    "        How do we know when we have reached the end of `yy`?  \n",
    "        For this course, you can just assume `len(yy)=len(xx)`.  \n",
    "        However, a more general design is to use `None` as an EOS\n",
    "        symbol.  If you prefer that design, then `iterate_y`\n",
    "        should also yield `None` if `y_prefix` can itself serve \n",
    "        as a legal output `yy`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def iterate_aa(self, *, xx):\n",
    "        \"\"\"\n",
    "        Returns an iterator over plans that are allowed for input `xx`.\n",
    "        The default implementation just calls `iterate_yy(xx=xx)`, which is \n",
    "        appropriate for prediction tasks where the plans simply correspond \n",
    "        to predicting the different outputs.  This can be overridden for\n",
    "        other kinds of decision tasks.\n",
    "        (See formalisms.pdf, \"Decision theory\" and \"More decision theory\".)\n",
    "        \"\"\"\n",
    "        yield from self.iterate_yy(xx=xx)\n",
    "        \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        \"\"\"\n",
    "        Return the reward that plan `aa` will get on input `xx` if the true answer is `yy`.\n",
    "        This method *defines* the reward function.\n",
    "        \"\"\"\n",
    "        assert yy is not None    # should appear in subclass implementations too \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def reward_threshold(self, *, xx):\n",
    "        \"\"\"\n",
    "        Return a value `t` such that we consider plans with reward >= `t` to be \"good\"\n",
    "        and plans with reward < `t` to be \"errors\".  This can be used for listing errors\n",
    "        and serves as additional documentation of the reward function.  Note that the\n",
    "        threshold may depend on `xx`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "c001b247-3f65-4d7f-8bbc-13f2edf72b7b",
    "deletable": false
   },
   "source": [
    "<a id=\"Problem_stresstask\"></a>\n",
    "## The vowel stress task\n",
    "Now let's instantiate that [`TaskSetting`](#TaskSetting) interface for our task of stressing vowels:  \n",
    "  * First fill in the function `StressTask.iterate_y` to iterate through the domain of $\\mathbf{y}_t$ conditioned on the input $\\mathbf{x}, \\mathbf{o}$ and the prefix of the y string $\\mathbf{y}_{0:t-1}$.  Test that it works.  \n",
    "  * Then go back to the parent class above and fill in `TaskSetting.iterate_yy`, so that it uses `iterate_y` to iterate through the entire domain of $\\mathcal{Y}_{\\mathbf{x}, \\mathbf{o}}$.  Sometimes the parameter `oo` will be `None` indicating that we instead want to iterate the domain of $\\mathcal{Y}_\\mathbf{x}$\n",
    "  \n",
    "*Python hints*: Some useful Python constructions are illustrated in the provided code below.  You can define an iterator in Python using `yield` as follows:\n",
    "```python\n",
    "def f():\n",
    "    yield 'a'\n",
    "    yield 'e'\n",
    "```\n",
    "Now you can write expressions like `list(f)` to build a list of the iterates, or write loops like this:\n",
    "```python\n",
    "for vowel in f():\n",
    "    print(vowel)\n",
    "```\n",
    "You may also find the `yield from` operator to be useful (look it up online!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "3d0c832f-95c2-4d66-b1de-da817029bb0c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class StressTask(TaskSetting):\n",
    "    \"\"\"\n",
    "    Class of models for the vowel stress problem, with\n",
    "    a simple 0-1 reward function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        assert yy is not None\n",
    "        return 1 if yy == aa else 0    # was the answer exactly right?\n",
    "    \n",
    "    def reward_threshold(self, *, xx):\n",
    "        return 1\n",
    "        \n",
    "    def iterate_y(self, *, xx, oo=None, yy_prefix):\n",
    "        \"\"\"\n",
    "        Iterate through the domain of y_t given xx, oo, yy_{0:t-1}.\n",
    "        \"\"\"\n",
    "        t = len(yy_prefix) \n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "   \n",
    "    def iterate_yy(self, *, xx, oo=None):\n",
    "        # Assert that the observable (if any) has the right format.\n",
    "        # (This is more efficient than checking within `iterate_y`,\n",
    "        # which would do the same checks repeatedly.)\n",
    "        if oo is not None:\n",
    "            assert len(oo) == len(xx)\n",
    "            for t in range(len(oo)):\n",
    "                assert oo[t] == xx[t] or (xx[t] in 'aeiou' \n",
    "                                          and (oo[t] == '?' or oo[t] == xx[t].upper()))\n",
    "        # Now just invoke the parent class's default `iterate_yy`, \n",
    "        # which calls our specialized `iterate_y`.\n",
    "        yield from super().iterate_yy(xx=xx, oo=oo)\n",
    "\n",
    "task = StressTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "bc4e50d3-02ae-43d3-a759-7572db4177df",
    "deletable": false
   },
   "source": [
    "Now, using that class, let's check that your `iterate_yy` correctly iterates over possible output strings given $\\mathbf{x}$ and optionally $\\mathbf{o}$.  We give you two test cases here to get started.  You should add your own test cases as well to this notebook cell.  \n",
    "\n",
    "(*Note*: Python uses `t = tuple(s)` and `s = ''.join(t)` to convert between a string `s` and a tuple `t` of its characters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "g.cell_uuid": "dfc5bfaa-d147-4809-a854-465f267c51f6",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "assert set(task.iterate_yy(xx=tuple('test'))) == {tuple('test'), tuple('tEst')}\n",
    "[''.join(yy) for yy in task.iterate_yy(xx=tuple('testphrase'), oo=tuple('t?stphrAs?'))]\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "g.cell_uuid": "8bab1539-b46b-4d68-91ec-4390ec3c5f12",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "for xx, oo, yy in iterate_data('dev', max_examples=5):\n",
    "    aa = task.iterate_aa(xx=xx)\n",
    "    task.reward(aa=aa, xx=xx, yy=yy)\n",
    "    print(''.join(list(aa)[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "36f1a6c8-f752-4127-9e83-b3b91d98d516",
    "deletable": false
   },
   "source": [
    "## Probability models\n",
    "To choose among the outputs `yy`, we'll want to make use of a probability model.\n",
    "\n",
    "A `ProbabilityModel` object specifies a conditional probability distribution $p_{\\boldsymbol{\\theta}}(\\mathbf{y} \\mid \\mathbf{x})$ with parameter vector $\\boldsymbol{\\theta}$.  The object has methods to evaluate probabilities, to sample from the distribution, and to train its parameters.  \n",
    "\n",
    "In order to compute probabilities $p(\\mathbf{y} \\mid \\mathbf{x})$ or to sample from the distribution, the object may need to be able to enumerate the domain $\\mathcal{Y}_{\\mathbf{x}}$.  That domain is specified by some instance of `TaskSetting`, which must be passed to the constructor and gets stored in `self.task`.\n",
    "\n",
    "The subclass `BoltzmannModel` specializes `ProbabilityModel`.  It uses $\\boldsymbol{\\theta}$ to define a `score` function that corresponds to $G_\\boldsymbol{\\theta}(\\mathbf{x}, \\mathbf{y})$, and then takes $p_{\\boldsymbol{\\theta}}(\\mathbf{y} \\mid \\mathbf{x}) \\propto \\exp G_\\boldsymbol{\\theta}(\\mathbf{x}, \\mathbf{y})$ \u2014 a Boltzmann distribution.\n",
    "\n",
    "Below we give the general interfaces.  For now, just read the code.  You will soon come back and fill in the `BoltzmannModel.prob` method (as well as `BoltzmannModel.normalizer`, which it calls).  Don't worry about `logprob_gradient` or `sample` yet: you'll fill those in even later in the assignment.\n",
    "\n",
    "The specific parameters and scoring method are not implemented in these generic classes.  We'll fill them in [below](#Problem_loglinstressmodel) in a subclass that defines a *particular* family of Boltzmann distributions \u2014 i.e., a particular probability model for our task.\n",
    "<a id=\"ProbabilityModel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "0c18fb5f-15f4-4528-9ef9-4e00b2bdeb0c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class ProbabilityModel(object):   \n",
    "    \"\"\"\n",
    "    Base class for conditional probability models P_theta(y | x).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task):\n",
    "        assert isinstance(task, TaskSetting)\n",
    "        self.task = task\n",
    "        self.initialize_params()\n",
    "    \n",
    "    def initialize_params(self):\n",
    "        \"\"\"\n",
    "        Reset the model parameters to their start state.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "       \n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\"\n",
    "        Return a copy of the parameter vector for this model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @params.setter\n",
    "    def params(self, new_param_vec):\n",
    "        \"\"\"\n",
    "        Update the parameters for the model to equal new_param_vec.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def prob(self, *, xx, oo=None, yy=None):\n",
    "        \"\"\"\n",
    "        Return p(yy | xx) or p(oo | xx).  Only one of `yy` or `oo` should be specified.\n",
    "        \n",
    "        If `yy` is not a legal string in self.task's output space, or `oo` is not a\n",
    "        legal observable, then we would ideally raise an error, but you are not \n",
    "        required to implement that.\n",
    "        \"\"\"\n",
    "        assert (oo is None) != (yy is None)   # should appear in subclass implementations too\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def uprob(self, *, xx, oo=None, yy=None):\n",
    "        \"\"\"\n",
    "        Just like `prob`, except that this version is free to return an \n",
    "        unnormalized probability when that is more efficient.\n",
    "        The default implementation just calls `prob`.\n",
    "        \"\"\"\n",
    "        return self.prob(xx=xx, oo=oo, yy=yy) \n",
    "        \n",
    "    def logprob_gradient(self, *, xx, oo=None, yy=None):  \n",
    "        \"\"\"\n",
    "        The gradient of log p(yy | xx) or log p(oo | xx) with respect to the \n",
    "        model parameters `params`, evaluated at the current model parameters.\n",
    "        \n",
    "        Either `yy` as a fully observed output or `oo` as a partial observation\n",
    "        should be specified, but not both. (See formalisms.pdf, \"Observations\".)\n",
    "        \n",
    "        This is typically used to help estimate the parameters of the model.\n",
    "        \"\"\"\n",
    "        assert (oo is None) != (yy is None)   # should appear in subclass implementations too\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def logprob_per_example(self, dataset):\n",
    "        \"\"\"\n",
    "        Return the log of the conditional probability assigned\n",
    "        by the model to an example, averaged over all examples\n",
    "        in the given dataset.  This is useful to check the predictive \n",
    "        power of the model `p(yy | xx)`.  \n",
    "        \n",
    "        For each example, this method will sum `log p(yy | xx)` if \n",
    "        `yy` is defined, and otherwise `log p(oo | xx)`.  It never \n",
    "        conditions on `oo`, since the model is intended to capture\n",
    "        `p(yy | xx)`.\n",
    "        \n",
    "        On a training dataset, this measures log-likelihood (how well\n",
    "        the model fits the training examples).  On a dev or test dataset\n",
    "        it measures held-out log-likelihood (how well the model predicts\n",
    "        held-out examples).\n",
    "        \n",
    "        The default implementation calls `prob`.\n",
    "        \"\"\"\n",
    "        total_logprob = 0\n",
    "        count = 0\n",
    "        for xx, oo, yy in dataset:\n",
    "            total_logprob += np.log(self.prob(xx=xx, oo=oo) if yy is None \n",
    "                                    else self.prob(xx=xx, yy=yy))\n",
    "            count += 1\n",
    "            if count % 50 == 0: sys.stdout.write('\\r\\tevaluated log-probability on {} examples'.format(count))\n",
    "        sys.stdout.write('\\n')\n",
    "        return total_logprob / count\n",
    "    \n",
    "    def sampler(self, *, xx, oo=None, temperature=1):\n",
    "        \"\"\"\n",
    "        Generates an infinite stream of samples `yy` drawn exactly\n",
    "        from p(`yy` | `xx`) or p(`yy` | `xx`, `oo`).\n",
    "        The default method uses brute force via `self.task.iterate_yy`. \n",
    "        \"\"\"\n",
    "        # Note: We return a stream to avoid redoing work when we want *many* samples.\n",
    "        # You should only have to compute the unnormalized probabilities and the \n",
    "        # normalizer once and then keep reusing them for the whole stream.\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def approx_sampler(self, *, xx, oo=None, temperature=1):\n",
    "        \"\"\"\n",
    "        An approximate version of `sampler`.\n",
    "        The default method uses Gibbs sampling, so successive samples in the\n",
    "        stream will be correlated.\n",
    "        \n",
    "        Caveat to users: Same caveat as at TaskSampler.iterate_yy.\n",
    "        \"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "a8f309ac-ff52-49a2-8bd0-aba87a4a9f15",
    "deletable": false
   },
   "source": [
    "<a id=\"BoltzmannModel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4b4ba020-118d-461e-8e59-6643c539b734",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class BoltzmannModel(ProbabilityModel):\n",
    "    \"\"\"\n",
    "    Base class for conditional probability models of the form\n",
    "    P_theta(y | x) = (1/Z(x)) exp (G_theta(x,y) / T),\n",
    "    that is, a Boltzmann distribution with temperature T.\n",
    "    We refer to G_theta(x,y) as a \"score\".\n",
    "    \"\"\"\n",
    "    \n",
    "    def score(self, *, xx, yy):\n",
    "        \"\"\"\n",
    "        Return the score G(`xx`, `yy`) as defined by the current params.\n",
    "        By default, call `score_with_gradient` and only return the score.\n",
    "        \"\"\"\n",
    "        score, gradient = self.score_with_gradient(xx=xx, yy=yy)\n",
    "        return score\n",
    "        \n",
    "    def score_with_gradient(self, *, xx, yy):\n",
    "        \"\"\"\n",
    "        Return two values: the score G(`xx`,`yy`) and its gradient with respect to the params.\n",
    "        It's often convenient to compute the gradient along with the score, and we'll sometimes\n",
    "        need the gradient.\n",
    "        This method usually *defines* G.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "  \n",
    "    def normalizer(self, *, xx, oo=None, temperature=1):\n",
    "        \"\"\"\n",
    "        The normalizing function `Z(xx)` or `Z(xx,oo)`, \n",
    "        often called the \"partition function\", that is used to define\n",
    "            p(yy | xx)     = \\frac{1}{Z(xx)}    exp G(...)\n",
    "            p(yy | xx, oo) = \\frac{1}{Z(xx,oo)} exp G(...)\n",
    "        (See formalisms.pdf, \"Marginal and conditional probabilities\".)\n",
    "        \n",
    "        The default implementation computes this by a brute-force sum with `iterate_yy`.\n",
    "        However, that could be overridden by a more efficient method when available, \n",
    "        or by an approximation.\n",
    "        \"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def uprob(self, *, xx, oo=None, yy=None, temperature=1):\n",
    "        assert (oo is None) != (yy is None)\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def prob(self, *, xx, oo=None, yy=None, temperature=1):\n",
    "        assert (oo is None) != (yy is None)\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "    def logprob_gradient(self, *, xx, oo=None, yy=None):\n",
    "        assert (oo is None) != (yy is None)\n",
    "        # Warning: Don't inadvertently recompute the same normalizer many times!  That's inefficient.\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "87e9439c-f7ef-4c78-8154-8a0679ef9cf9",
    "deletable": false
   },
   "source": [
    "<a id=\"Problem_loglinstressmodel\"></a>\n",
    "## Building a model for the stress task\n",
    "\n",
    "We will design a simple linear scoring function $G_\\boldsymbol{\\theta}(\\mathbf{x}, \\mathbf{y})$.  This means that our probability model will be log-linear.\n",
    "\n",
    "Our class `LoglinearStressModel` will define a simple linear scoring function $G_\\boldsymbol{\\theta}$, using hand-written features whose weights are specified by the parameter vector $\\boldsymbol{\\theta}$.\n",
    "Its `score` method can return a score $G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y}) \\in \\mathbb{R} \\cup \\{ -\\infty \\}$, so you could write code like this:\n",
    "```python\n",
    "from math import inf \n",
    "model = LoglinearStressModel(task)\n",
    "assert model.score(xx=xx, yy=yy) == -inf\n",
    "```\n",
    "\n",
    "An instance of the class specifies a particular value for the parameters.  Its parameter vector $\\boldsymbol{\\theta}$ can be examined via the `params` property, and should be updated like this:\n",
    "```python\n",
    "update = np.zeros_like(model.params)  # a zero vector with the same dimensionality as params\n",
    "update[7] = 123                       # put some nonzero elements into that vector\n",
    "update[8] = 456\n",
    "model.params += update                # add it to params (+= makes Python invoke set_params)\n",
    "```\n",
    "This may seem a bit roundabout: why not just modify `params` directly via statements like `model.params[7] += 123`?  The reason is that the object does not actually have a `params` attribute.  Its parameters are stored in one or more attributes with other names.  Calling `params` invokes a \"getter\" function (the `params` property) that constructs a new vector of all those parameters.  Modifying that new vector would not change the original parameters, whereas calling `params += ...` invokes a \"setter\" function that does so.\n",
    "\n",
    "To make clear which parts of the definition are shared by all log-linear models, we start by defining a generic `LoglinearModel` class with a simple feature vector, which may be useful later.  Our `LoglinearStressModel` is a *particular* subclass \u2014 that is, a particular linear scoring model.  It could be further subclassed to give richer models with more features.  The  brute-force methods on this assignment make no assumption about what $G$ looks like, so you would be free to define $G$ using crazy features (\"is the number of stressed vowels prime?\" \"what is the score of `yy` according to a certain neural network?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6e5dc8be-8deb-4dbb-ad7d-e7b5f3063c35",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class LoglinearModel(BoltzmannModel):  \n",
    "    \"\"\"\n",
    "    A base class for log-linear models: \n",
    "    These are just Boltzmann models with linear scoring functions,\n",
    "    so we inherit from BoltzmannModel.\n",
    "    We assume that the parameters can be stored in an attribute `_theta`.\n",
    "    The training method is still not defined here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task):\n",
    "        super().__init__(task)\n",
    "        self.initialize_params()\n",
    "\n",
    "    def initialize_params(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        return np.array(self._theta)\n",
    "\n",
    "    @params.setter\n",
    "    def params(self, val):\n",
    "        assert np.isfinite(val).all()\n",
    "        self._theta[:] = val\n",
    "\n",
    "    def features(self, *, xx, yy):\n",
    "        \"\"\"Extract a feature vector that measures various features of the pair (xx,yy).\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def score_with_gradient(self, *, xx, yy):\n",
    "        \"\"\"\n",
    "        Return two values: the score G(`xx`,`yy`) and its gradient with respect to the params.\n",
    "        It's convenient to compute the gradient along with the score, and we'll need it later.\n",
    "        \"\"\"\n",
    "        # The score is the dot product of params theta with the feature vector,\n",
    "        # which implies that its gradient is just the feature vector.\n",
    "        f = self.features(xx=xx, yy=yy)\n",
    "        score = self._theta.dot(f)    \n",
    "        return float(score), f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "dc7eb74a-f16c-4c05-bf75-571b3379e22c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class LoglinearStressModel(LoglinearModel):\n",
    "    \n",
    "    \"\"\"\n",
    "    A specific log-linear model for StressTask.\n",
    "    \"\"\"   \n",
    "    def __init__(self):\n",
    "        super().__init__(StressTask())   # specify which task this model is for\n",
    "    \n",
    "    def initialize_params(self):\n",
    "        np.random.seed(42)\n",
    "        self._theta = np.array([\n",
    "            .1,\n",
    "            .05,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "        ])\n",
    "\n",
    "    def features(self, *, xx, yy):\n",
    "        string = ''.join(yy)                          # concatenate symbols into an ordinary python string\n",
    "        vowels = re.sub(r'[^aeiouAEIOU]','', string)  # extract just the vowels\n",
    "        \n",
    "        # All of our features are counts of structures in `(xx,yy)`.\n",
    "        # For this problem, the features don't need to look at `xx`, but features for a POS tagger would do that.\n",
    "        uppercase_vowels = len(re.findall(r'[AEIOU]', vowels))\n",
    "        altcase_vowels = len(re.findall(r'(?=([aeiou][AEIOU])|([AEIOU][aeiou]))', vowels))\n",
    "        enduppercase_vowels = len(re.findall(r'[AEIOU]$', vowels))\n",
    "        uppercase_consonants = len(re.findall(r'[TNSRHDLC]', string))  \n",
    "        length = len(string)\n",
    "\n",
    "        # Assemble those counts into a feature vector.\n",
    "        return np.array([uppercase_vowels,\n",
    "                         altcase_vowels,\n",
    "                         enduppercase_vowels,\n",
    "                         uppercase_consonants,\n",
    "                         length])\n",
    "\n",
    "\n",
    "model = LoglinearStressModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "abb125d6-5506-4fde-9fe6-8f39e60edcb0",
    "deletable": false
   },
   "source": [
    "Let's try the model out with its default initial parameter setting.  \n",
    "What is each feature doing in the cell below?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6bba6096-8ae7-4f52-af57-18aead4c983b",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "301b5a82-29ec-46fe-bada-91e8801d190a",
    "deletable": false
   },
   "source": [
    "Why don't the fourth and fifth features help to discriminate among the `yy` candidates?  Will that be true for every `xx`, or just for `xx=testphrase`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "7d40fffb-ca84-4b51-b42b-849059f13a4f",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e9b7fc97-6289-4eb4-8dc3-8c7b19d140ad",
    "deletable": false
   },
   "source": [
    "To understand the features, it will probably help to experiment, so you may want to add your own examples to the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4bb00988-729f-48ac-a42e-5e62875d61cc",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "testphrase = tuple('testphrase')\n",
    "[( ''.join(yy),                                   # string yy\n",
    "   model.features(xx=testphrase, yy=yy),   # yy's feature vector with this xx\n",
    "   model.score(xx=testphrase, yy=yy)  )    # yy's score with this xx, using the current parameters \n",
    " for yy in task.iterate_yy(xx=testphrase)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "36bf8f33-964c-4b93-8e16-37192b57a438",
    "deletable": false
   },
   "source": [
    "Now go back to [BoltzmannModel](#BoltzmannModel) and fill in the `normalizer` and `prob` methods.\n",
    "\n",
    "Let's check your implementation.  \n",
    "Using the scores above, give simple numerical expressions (which may refer to $Z$) for:\n",
    "\n",
    "$p(\\mathbf{Y}=\\texttt{testphrAsE} \\mid \\mathbf{X}=\\texttt{testphrase}) =$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "70d69c37-81bb-492c-b9ac-ff39790588f0",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1655feac-dc84-4cbb-b496-5fc70b7e60aa",
    "deletable": false
   },
   "source": [
    "$p(\\mathbf{Y} \\in \\texttt{testphrAs?} \\mid \\mathbf{X}=\\texttt{testphrase}) =$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6c7ee4bc-fdde-4e3b-8eb0-44897d76986d",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6fdfb413-3864-47c9-ba3f-4dd9af0bf6a6",
    "deletable": false
   },
   "source": [
    "where $\\texttt{testphrAs?}$ is being informally used to mean the *set* of output strings compatible with that partial observation.  \n",
    "Those numerical expressions should match the answers computed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "549d619b-e707-422e-be34-20ede12ac065",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "Z = model.normalizer(xx=testphrase)\n",
    "from math import isclose\n",
    "assert isclose(Z, 9.812839692144227)  # checks that you got the right value\n",
    "\n",
    "[Z, \n",
    " model.prob(xx='testphrase',yy='testphrAsE'),\n",
    " model.prob(xx='testphrase',oo='testphrAsE'),  # should be the same as previous line\n",
    " model.prob(xx='testphrase',oo='testphrAs?')]  # should be bigger than previous line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d24c79eb-efd5-4b56-936c-aa247f7b590d",
    "deletable": false
   },
   "source": [
    "Print out the whole distribution over `yy` for `xx='testphrase'` (using your iterator \u2014 this can be done in one line of Python).  \n",
    "What happens if you raise or lower the temperature? Give some tests and discussion here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c4c0d7e1-e490-439e-aa9e-56823dafced8",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "T = 1\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ee23bcf7-d57b-466c-99c4-ebe27404df4b",
    "deletable": false
   },
   "source": [
    "**Discussion:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "f8a2a9e5-3b9f-415b-a9b2-2d005d978693",
    "deletable": false
   },
   "source": [
    "## Decision rules \n",
    "A `DecisionAgent` has a specific rule for making decisions in a given `TaskSetting` (namely `self.task`) by consulting a given `ProbabilityModel` (namely `self.model`).  As before, let's start with a general interface.\n",
    "<a id=\"DecisionAgent\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "cf75d4a5-c28a-40f6-8381-e036d9797921",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class DecisionAgent(object):\n",
    "    \"\"\"\n",
    "    Base class for the decision agents in this homework.\n",
    "    \n",
    "    The `decision` function in subclasses should implement some\n",
    "    decision rule, which may refer to `self.task` (a `TaskSetting`)\n",
    "    and `self.model` (a `ProbabilityModel`).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task, model):\n",
    "        \"\"\"\n",
    "        Arguments to the constructor are a TaskSetting \n",
    "        and a ProbabilityModel.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert isinstance(task, TaskSetting)\n",
    "        assert isinstance(model, ProbabilityModel)\n",
    "        self.model = model\n",
    "        self.task = task\n",
    "    \n",
    "    def decision(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        Return some action `aa` that is appropriate to input `xx` and the partially\n",
    "        observed output `oo` (if any).  \n",
    "        \n",
    "        This is the agent's decision rule.  It might make use of `model`, `reward`, \n",
    "        `iterate_aa`, and/or a random number generator.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "            \n",
    "    def test(self, dataset):\n",
    "        \"\"\"\n",
    "        Run the decision rule on all the examples in `dataset` \n",
    "        and return the average reward.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        count = 0\n",
    "        for xx, oo, yy in dataset:\n",
    "            aa = self.decision(xx=xx, oo=oo)\n",
    "            reward += self.task.reward(aa=aa, xx=xx, yy=yy)\n",
    "            count += 1\n",
    "            if count % 50 == 0: sys.stdout.write('\\r\\tevaluated reward on {} examples'.format(count))\n",
    "        sys.stdout.write('\\n')\n",
    "        return reward / count\n",
    "    \n",
    "    def show_errors(self, dataset, max_examples=20, reward_threshold=None):\n",
    "        \"\"\"\n",
    "        Print (up to) `max_examples` examples in which the decision\n",
    "        rule made a \"bad\" decision \u2014 one with reward < `reward_threshold`.\n",
    "        `reward_threshold` may be a constant number or a function of the input `xx`,\n",
    "        By default, it is the method task.reward_threshold.\n",
    "        \"\"\"\n",
    "        # Modify reward_threshold if needed so that it's a function of `xx`\n",
    "        if not callable(reward_threshold):\n",
    "            if reward_threshold is None:\n",
    "                reward_threshold = lambda xx: task.reward_threshold(xx=xx)\n",
    "            else:  # it should be a constant number\n",
    "                threshold = reward_threshold\n",
    "                reward_threshold = lambda xx: threshold\n",
    "                \n",
    "        # Iterate over the data\n",
    "        for xx, oo, yy in dataset:\n",
    "            aa = self.decision(xx=xx, oo=oo)\n",
    "            r = self.task.reward(aa=aa, xx=xx, yy=yy)\n",
    "            if r < reward_threshold(xx):\n",
    "                print(\" r: {r}\\n\\tyy: {yy}\\n\\taa: {aa}\\n\\txx: {xx}\\n\\too: {oo}\".format(\n",
    "                     r=r,\n",
    "                    xx=''.join(xx),\n",
    "                    oo=''.join(oo),\n",
    "                    yy=''.join(yy),\n",
    "                    aa=''.join(aa),\n",
    "                ))\n",
    "                max_examples -= 1\n",
    "                if max_examples == 0: break\n",
    "                    \n",
    "    ## The following methods are discussed later in the assignment.\n",
    "    ## They ensure that decision agents are trainable.\n",
    "                    \n",
    "    def stochastic_gradient(self, **kwargs):\n",
    "        \"\"\"\n",
    "        In general, a decision agent might have its own parameters, which\n",
    "        it might train in such a way as to maximize reward.  (This is \n",
    "        particularly important in reinforcement learning.)\n",
    "        \n",
    "        By default, however, if the agent is asked to train on an example, it \n",
    "        will simply use the example to train the underlying probability model.\n",
    "        \"\"\"\n",
    "        return self.model.stochastic_gradient(**kwargs)\n",
    "        \n",
    "    # By default, the params of the decision agent are the params of the underlying model.\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.model.params\n",
    "\n",
    "    @params.setter\n",
    "    def params(self, val):\n",
    "        self.model.params = val   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "4d84f188-ca8e-416c-97dd-ac3cf6f39254",
    "deletable": false
   },
   "source": [
    "## The Viterbi decision rule\n",
    "Our agent needs a decision rule.  Define a \"Viterbi\" decision rule that chooses the *most probable* `yy` given the input `xx`.  In the case of a Boltzmann model, that is also the `yy` that scores highest with `xx`:\n",
    "$$\\text{argmax}_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}}} G_\\boldsymbol{\\theta}(x, y)$$\n",
    "\n",
    "If `oo` is specified, the rule should choose the most probable `yy` that is *compatible* with `oo`:\n",
    "$$\\text{argmax}_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x},\\mathbf{o}}} G_\\boldsymbol{\\theta}(x, y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c5457633-d458-4c76-a223-e8baa09fb779",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class ViterbiAgent(DecisionAgent):\n",
    "\n",
    "    def decision(self, *, xx, oo=None):\n",
    "        \"\"\"The Viterbi decision rule.\"\"\"\n",
    "        # Hint: Use self.task.iterate_yy and self.model.\n",
    "        # Warning: Don't inadvertently recompute the same normalizer many times!  That's inefficient.\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b9cca6fb-a301-44b3-bac3-f5f3092cd3b1",
    "deletable": false
   },
   "source": [
    "Now let's make a Viterbi agent for our task, using our probability model.  Check that it is behaving as you expect, by trying out some more test cases in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4295e9ea-abea-4954-a0dc-dce5998be30c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "viterbi_agent = ViterbiAgent(task, model)\n",
    "\n",
    "viterbi_agent.decision(xx='testphrase')\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0b124659-4187-4f7a-85b1-336c215b2730",
    "deletable": false
   },
   "source": [
    "Let's see what kind of predictions the agent makes on *development* data.  \n",
    "(We haven't trained its parameters yet.)\n",
    "\n",
    "In the code below, fill in assignments to `aa` (the prediction) and `reward` (the reward received as a result), so that the code prints out tuples $(R, \\mathbf{x}, \\mathbf{o}, \\mathbf{y}, \\mathbf{a})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "246a311b-9aba-40f7-b5cb-6125ac45eb05",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "for xx, oo, yy in iterate_data('dev', max_examples=5):\n",
    "    aa = reward = None  # replace with actual computation below\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    print((reward,\n",
    "           ''.join(xx),\n",
    "           ''.join(oo) if oo is not None else None,\n",
    "           ''.join(yy) if yy is not None else None,\n",
    "           ''.join(aa)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "04390a49-69ab-45ef-904e-b1a809195f46",
    "deletable": false
   },
   "source": [
    "Let's use the development dataset to check the overall quality of our predictions.\n",
    "This returns the *average reward* over all development examples (so higher values are better).\n",
    "Since we defined reward to be 1 if `aa==yy` and otherwise 0, our average reward is the *fraction* of examples where the agent predicted `yy` exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a97678d6-9685-4370-b8e7-0f0228d731c1",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "viterbi_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "95e5f61e-e3b9-463d-ba83-3e3a8515b64c",
    "deletable": false
   },
   "source": [
    "Some of our \"success\" probably came from the fact that the dev data included partial observations $\\mathbf{o}$ of the output $\\mathbf{y}$, so the agent only had to pick the output from the set $\\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}, \\mathbf{o}}$ of outputs that are compatible with $\\mathbf{o}$.\n",
    "\n",
    "How much worse would we have done without $\\mathbf{o}$, so that we have to pick the right output from the larger  set $\\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "330b9b07-c25a-4954-bf29-40dde94f1866",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# iterate over modified versions of the examples, in which oo is replaced by None\n",
    "viterbi_agent.test([(xx,None,yy) for (xx,oo,yy) in iterate_data('dev')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "aa8d6699-3aa5-4381-b546-f2a268dc4270",
    "deletable": false
   },
   "source": [
    "You may want to try out the `show_errors` method as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a4ac3762-4b7f-4c11-a842-85ec5cb5017b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "viterbi_agent.show_errors(iterate_data('dev'), max_examples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5570ad48-e2ad-4d81-a6e3-f457532a7b36",
    "deletable": false
   },
   "source": [
    "<a id=\"sup-training\"></a>\n",
    "## Gradients for supervised training\n",
    "\n",
    "Our training objective below will include terms of the form $\\log p_\\boldsymbol{\\theta}(\\mathbf{y}_n \\mid \\mathbf{x}_n)$.  \n",
    "Recall that in the case of a Boltzmann distribution (at temperature 1), we have\n",
    "$$\\begin{align*}\n",
    "\\log p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x}) \n",
    "&= \\log \\frac{\\exp G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y})}{Z(\\mathbf{x})} \\\\\n",
    "&= G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y}) - \\log Z(\\mathbf{x})\n",
    "\\end{align*}$$\n",
    "In general, the gradient of $\\log Z$ will be the expected gradient of $G$.  Thus, the gradient of the above log-probability takes the classic form\n",
    "$$\\nabla_\\boldsymbol{\\theta} \\log p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x}) \n",
    "= \\nabla_\\boldsymbol{\\theta} G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y}) \n",
    "   - \\sum_{\\mathbf{y'} \\in \\mathcal{Y}_{\\mathbf{x}}}\n",
    "      p_\\boldsymbol{\\theta}(\\mathbf{y'} \\mid \\mathbf{x}) \\nabla_\\boldsymbol{\\theta} G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y'})$$\n",
    "In the special case of a log-linear model, where $G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y}) = \\boldsymbol{\\theta} \\cdot \\mathbf{f}(\\mathbf{x},\\mathbf{y})$, this reduces to the familiar expression *observed features minus expected features*,\n",
    "$$\\nabla_\\boldsymbol{\\theta} \\log p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x}) \n",
    "= \\boldsymbol{f}(\\mathbf{x},\\mathbf{y}) \n",
    "   - \\sum_{\\mathbf{y'} \\in \\mathcal{Y}_{\\mathbf{x}}}\n",
    "      p_\\boldsymbol{\\theta}(\\mathbf{y'} \\mid \\mathbf{x}) \\cdot \\boldsymbol{f}(\\mathbf{x},\\mathbf{y'})$$\n",
    "which you should recall from the [log-linear handout](https://www.cs.jhu.edu/~jason/tutorials/loglin/formulas.pdf), section 4.  We've merely generalized that derivation to non-linear $G$ functions by writing $\\nabla G$ instead of $\\boldsymbol{f}$.  It's really the same derivation.  \n",
    "\n",
    "In the log-linear case, this log-probability is a concave function of $\\boldsymbol{\\theta}$; but with non-linear $G$ functions, it will generally suffer from local maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e0390943-4cc0-4225-934d-87edbb2b87e0",
    "deletable": false
   },
   "source": [
    "*Exercise*: It was claimed above that for a Boltzmann distribution at temperature 1,\n",
    "$$\\nabla_\\theta \\log Z(x) \n",
    "   = \\sum_{y' \\in \\mathcal{Y}_x} \n",
    "      p_\\theta(\\mathbf{y'} \\mid \\mathbf{x}) \n",
    "      \\cdot \\nabla_\\theta G(x,y')$$\n",
    "Prove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "55818e59-653d-443a-ab02-b1a424d3f77c",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "7871773b-6138-43c7-89c9-3aa451edf267",
    "deletable": false
   },
   "source": [
    "## Gradients for partially supervised training\n",
    "\n",
    "More generally, if the $n$th training example is only partially observed, we replace $\\mathbf{y}_n$ in the [supervised objective](#sup-training)\n",
    "with the partial observation $\\mathbf{o}_n$.  The modified term $p_\\boldsymbol{\\theta}(\\mathbf{o}_n \\mid \\mathbf{x}_n)$ must sum over all possible values of $\\mathbf{y}_n$, which is now a *latent variable*.  So the objective contains a log of a sum.  \n",
    "\n",
    "We now have\n",
    "$$\\log p_\\boldsymbol{\\theta}(\\mathbf{o} \\mid \\mathbf{x}) \n",
    "= \\sum_{\\mathbf{y} \\in \\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}} p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x})\n",
    "= \\log \\frac{Z(\\mathbf{x},\\mathbf{o})}{Z(\\mathbf{x})} = \\log Z(\\mathbf{x},\\mathbf{o}) - \\log Z(\\mathbf{x})$$\n",
    "\n",
    "Partial observations (or equivalently latent variables) will generally introduce local maxima, even for a log-linear model.  Why?  We were lucky with the fully supervised version \u2014 a linear function minus a convex function is concave.  But the unsupervised log-linear objective is a convex function minus a convex function, which guarantees nothing.\n",
    "\n",
    "Nonetheless, this generalization doesn't change our computations too much.\n",
    "Remembering that the gradient of $\\log Z$ is the expected gradient of $G$, we get\n",
    "$$\\nabla_\\boldsymbol{\\theta} \\log p_\\boldsymbol{\\theta}(\\mathbf{o} \\mid \\mathbf{x}) \n",
    "= \\sum_{\\mathbf{y} \\in \\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}}\n",
    "      p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{o}) \\cdot\n",
    "        \\nabla_\\boldsymbol{\\theta} G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y}) \n",
    "   - \\sum_{\\mathbf{y'} \\in \\mathcal{Y}_{\\mathbf{x}}}\n",
    "      p_\\boldsymbol{\\theta}(\\mathbf{y'} \\mid \\mathbf{x}) \n",
    "      \\nabla_\\boldsymbol{\\theta} G_\\boldsymbol{\\theta}(\\mathbf{x},\\mathbf{y'})$$\n",
    "The two terms in this expression arise from $Z(\\mathbf{x},\\mathbf{o})$ and $Z(\\mathbf{x})$ respectively, so they are sometimes called the *numerator* and *denominator* terms.  \n",
    "In the special case of a log-linear model, the expression is simply a difference of two expected feature vectors:\n",
    "$$\\nabla_\\boldsymbol{\\theta} \\log p_\\boldsymbol{\\theta}(\\mathbf{o} \\mid \\mathbf{x}) \n",
    "= \\sum_{\\mathbf{y} \\in \\mathcal{Y}_{\\mathbf{x},\\mathbf{o}}}\n",
    "      p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{o}) \\cdot \\boldsymbol{f}(\\mathbf{x},\\mathbf{y})     \n",
    "   - \\sum_{\\mathbf{y'} \\in \\mathcal{Y}_{\\mathbf{x}}}\n",
    "      p_\\boldsymbol{\\theta}(\\mathbf{y'} \\mid \\mathbf{x}) \\cdot \\boldsymbol{f}(\\mathbf{x},\\mathbf{y'})$$\n",
    "\n",
    "Crucially, the two expectations are taken under different distributions: the \"clamped\" and \"free\" distributions.  \n",
    "In the positive expectation, the random variable $\\mathbf{Y}$ is (partially) \"clamped\" to match a complete observation $\\mathbf{y}$ or a partial observation $\\mathbf{o}$.  \n",
    "In the negative expectation, the random variable $\\mathbf{Y}$ is \"free\" to take on any value in $\\mathcal{Y}_{\\mathbf{x}}$.  \n",
    "In both cases, the current model $p_\\boldsymbol{\\theta}$ is used to assign relative weights to the possible values of $\\mathbf{Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "81b21bb2-e3c2-4304-be43-f35627d6c120",
    "deletable": false
   },
   "source": [
    "At this point, you should go back to [BoltzmannModel](#BoltzmannModel) and fill in the `logprob_gradient` method, which can compute both fully and partially supervised gradients according to how it is called.  (If you prefer, you could implement only the fully supervised branch now, and fill in the other branch later.)  \n",
    "\n",
    "Since the fourth and fifth features in `LoglinearStressModel` are not useful, the partial derivatives with respect to their weights should be about 0.  In general, the gradient should try to raise the weights of features whose values were observed to be larger in `yy`, or expected given `oo` to be larger in `yy`, than they are in the average candidate `yy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "621b97e3-a823-4a9a-9e6e-f3b344e634c3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "[model.logprob_gradient(xx='testphrase',yy='testphrAsE'),\n",
    " model.logprob_gradient(xx='testphrase',oo='testphrAsE'),  # should be the same as previous line\n",
    " model.logprob_gradient(xx='testphrase',oo='testphrAs?')]  # should be different from previous line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2f58e9f8-e379-4d4e-bca0-79cd33d3341e",
    "deletable": false
   },
   "source": [
    "## Stochastic gradient ascent\n",
    "\n",
    "To train our probability model, we will tune $\\boldsymbol{\\theta}$ to maximize the *training objective* $$(\\sum_{n=1}^N \\log p_\\boldsymbol{\\theta}(\\mathbf{y}_n \\mid \\mathbf{x}_n)) - c \\cdot || \\boldsymbol{\\theta} ||^2$$\n",
    "(or the more general version in which $\\mathbf{o}_n$ replaces $\\mathbf{y}_n$).\n",
    "This objective is known as *L2-regularized conditional log-likelihood*.  The regularization coefficient $c > 0$ encourages keeping $\\boldsymbol{\\theta}$ close to $\\mathbf{0}$.  \n",
    "\n",
    "When using stochastic gradient ascent, it is useful to scale this down by a factor of $N$ (which doesn't change the optimal $\\boldsymbol{\\theta}$), so that our actual objective is\n",
    "$$\\begin{align*}\n",
    "F(\\boldsymbol{\\theta}) \n",
    "&= (\\frac{1}{N} \\sum_{n=1}^N \\log p_\\boldsymbol{\\theta}(\\mathbf{y}_n \\mid \\mathbf{x}_n)) - \\frac{c}{N} || \\boldsymbol{\\theta} ||^2 \\\\\n",
    "&= \\text{mean}_{n=1}^N F_n(\\boldsymbol{\\theta}) \\\\\n",
    "\\text{where }\n",
    "F_n(\\boldsymbol{\\theta}) & = \\log p_\\boldsymbol{\\theta}(\\mathbf{y}_n \\mid \\mathbf{x}_n) - \\frac{c}{N} || \\boldsymbol{\\theta} ||^2\n",
    "\\end{align*}$$\n",
    "\n",
    "As a result, \n",
    "$\\nabla_\\boldsymbol{\\theta} F(\\boldsymbol{\\theta}) \n",
    "= \\text{mean}_{n=1}^N \\nabla_\\boldsymbol{\\theta} F_n(\\boldsymbol{\\theta})$.  That is, the gradient of $F_n$ is, *on average*, equal to the gradient of $F$.  \n",
    "\n",
    "Stochastic gradient ascent was taught in the reading handout for [NLP homework 3](https://www.cs.jhu.edu/~jason/465/hw-lm/hw-lm.pdf), section H.  You should review that handout; but the idea is that at each step, we'll choose a random example $n$ and nudge $\\theta$ in the direction of its gradient $\\nabla_\\boldsymbol{\\theta} F_n(\\boldsymbol{\\theta})$ \u2014 which is a good direction on average.  The forcefulness of this nudge (the \"step size\") decreases slowly over time.\n",
    "\n",
    "The gradient on example $n$ is clearly\n",
    "$$\\nabla_\\boldsymbol{\\theta} F_n(\\boldsymbol{\\theta}) = \\nabla_\\boldsymbol{\\theta} \\log p_\\boldsymbol{\\theta}(\\mathbf{y}_n \\mid \\mathbf{x}_n) - \\frac{2c}{N} \\boldsymbol{\\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1f416968-9b49-4904-9b8e-c6f85224e61a",
    "deletable": false
   },
   "source": [
    "### Implementing online training\n",
    "\n",
    "Stochastic gradient ascent is an example of an \"online\" training algorithm \u2014 that is, it visits (randomly chosen) examples one at a time.  In our implementation, an object is \"trainable\" by an online gradient-based algorithm if it implements a `stochastic_gradient` method that can be given a single training example.  \n",
    "\n",
    "So, let's equip our probability model with such a method.\n",
    "\n",
    "(*Note:* Some other training algorithms are \"batch\" algorithms that consider the entire dataset at once.  We won't be using those, but here's how we could add them: an object would be trainable by a batch gradient-based algorithm if it implements a `batch_objective_with_gradient` method that can be given an entire dataset.)\n",
    "\n",
    "It is traditional for optimization libraries to provide methods to *minimize* their functions, such as stochastic gradient *descent*.   To be compatible with such libraries, we will assume that a trainable object wants its objective function to be *minimized*.  So we will negate our actual objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "693627c3-d7d4-468f-bafa-cd926b36f34d",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class L2LogLikelihood:\n",
    "    \"\"\"\n",
    "    This class can be mixed into a ProbabilityModel to \n",
    "    set a training objective of maximizing its L2-regularized\n",
    "    log-likelihood, or equivalently, minimizing the negation\n",
    "    of that.\n",
    "    \n",
    "    `regularization_coeff` is an attribute that can be modified\n",
    "    directly and can also be specified by a keyword argument to\n",
    "    the constructor.  The same is true for `num_examples`.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, regularization_coeff=1, num_examples=None, **kwargs):\n",
    "        assert regularization_coeff >= 0\n",
    "        assert num_examples is None or num_examples >= 0\n",
    "        self.regularization_coeff = regularization_coeff\n",
    "        self.num_examples = num_examples\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def batch_objective_with_gradient(self, dataset):\n",
    "        raise NotImplementedError()     # not needed for this assignment, and probably not for this course\n",
    "\n",
    "    def stochastic_gradient(self, *args, **kwargs):   \n",
    "        \"\"\"\n",
    "        Note that num_examples must be specified for the stochastic \n",
    "        gradient case, so that the regularization term can be partitioned\n",
    "        among all the training examples.\n",
    "        \"\"\"\n",
    "        return -(self.logprob_gradient(*args, **kwargs) \n",
    "                 - (2 * self.regularization_coeff / self.num_examples) * self.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "g.cell_uuid": "00bf3333-65a5-4de1-97d3-090005b1ec15",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Multiple inheritance\n",
    "class TrainableLoglinearStressModel(L2LogLikelihood, LoglinearStressModel):\n",
    "    pass\n",
    "\n",
    "# Redefine `model` to be a trainable version\n",
    "model = TrainableLoglinearStressModel(regularization_coeff=15)\n",
    "\n",
    "# Confirm that the model can compute the stochastic gradient of its training objective\n",
    "model.num_examples = 1000    # must specify this in order to use stochastic_gradient method\n",
    "[model.logprob_gradient(xx='testphrase',yy='testphrAsE'),\n",
    " model.stochastic_gradient(xx='testphrase',yy='testphrAsE')]   # will be different from previous line: \n",
    "                                                               # should be slightly modified by regularizer, \n",
    "                                                               # and also negated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "368533a4-3678-4752-aedc-959c94f13e50",
    "deletable": false
   },
   "source": [
    "Now we can define a general-purpose SGD training algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "bddc4445-11c2-40ab-ac1a-3d4e12e374cf",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "class SGDTrainer(object):\n",
    "    \"\"\"\n",
    "    Algorithm for training any object by stochastic gradient ascent,\n",
    "    starting at its current parameters.  The object must implement a \n",
    "    `stochastic_gradient` method and have a `params` property.\n",
    "    \"\"\"\n",
    "    def __init__(self, *, epochs=1, init_stepsize=0.05, decay=0):   # could add other convergence criteria\n",
    "        self.epochs = epochs\n",
    "        self.init_stepsize = init_stepsize\n",
    "        self.decay = decay\n",
    "    \n",
    "    def train(self, trainable, dataset):\n",
    "        iteration = 0              # count the number of updates so far\n",
    "        dataset = list(dataset)    # make an internal copy\n",
    "        print('\\ttraining on dataset of {} examples'.format(len(dataset)))\n",
    "        for _ in range(self.epochs):\n",
    "            shuffle(dataset)       # permute in place so that the examples are visited in a random order\n",
    "            for example in dataset:   \n",
    "                example = dict(example._asdict())   # unpack named tuple into regular tuple\n",
    "                stepsize = self.init_stepsize / (1 + self.init_stepsize * self.decay * iteration)   \n",
    "                      # stepsize decreases slowly over time\n",
    "                trainable.params -= stepsize * trainable.stochastic_gradient(**example)\n",
    "                iteration = iteration+1\n",
    "                if iteration % 50 == 0: \n",
    "                    sys.stdout.write('\\r\\ttrained for {} iterations'.format(iteration))  # print progress\n",
    "        sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "98b128d4-79c8-4221-86bb-816d42038665",
    "deletable": false
   },
   "source": [
    "Let's try out the whole thing, starting from scratch to see how the pieces are put together.  \n",
    "\n",
    "Notice that we arranged for [DecisionAgent](#DecisionAgent) itself to be trainable \u2014 by default, it just passes the training examples along to train the probability model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f2b64c70-2bdc-47ee-b250-46dabf47bb09",
    "deletable": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "g.cell_uuid": "ef52ad0c-bd8c-4e8b-a350-38aacac580f4",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# First, our task setting.\n",
    "task = StressTask()\n",
    "\n",
    "# Next, a training dataset for that task.  Let's store it in a list so we know how big it is.\n",
    "trainset = list(iterate_data('train'))\n",
    "\n",
    "# Now a conditional probability model with an L2-regularized \n",
    "# conditional log-likelihood objective that can be trained online.\n",
    "class TrainableLoglinearStressModel(L2LogLikelihood, LoglinearStressModel):\n",
    "    pass\n",
    "c = 15\n",
    "N = len(trainset)\n",
    "model = TrainableLoglinearStressModel(regularization_coeff=c, num_examples=N)\n",
    "\n",
    "# An agent for solving the task using the model.\n",
    "viterbi_agent = ViterbiAgent(task, model)   # update agent to use the new version of the model\n",
    "print(\"Average dev reward before training: {}\".format(viterbi_agent.test(iterate_data('dev'))))\n",
    "\n",
    "# A method for training the agent (which trains the underlying model).\n",
    "trainer = SGDTrainer(epochs=2, decay=2*c/N)\n",
    "\n",
    "# So let's train!\n",
    "trainer.train(viterbi_agent, trainset)\n",
    "print(\"Average dev reward after training: {}\".format(viterbi_agent.test(iterate_data('dev'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6001f5f8-2542-425d-961b-00c19afa8ba8",
    "deletable": false
   },
   "source": [
    "You might sometimes want to train on a smaller dataset (check out the arguments to `iterate_data`).\n",
    "It's interesting to see how performance changes as you reduce the amount of training data, and it's certainly faster while you get your code running. \n",
    "\n",
    "*Advanced note:* How did we choose the `decay` hyperparameter for SGD?  [Bottou (2012)](http://research.microsoft.com/pubs/192769/tricks-2012.pdf) says that the decay rate should be higher if the function is curvier.  We don't know the curvature of the objective function at the optimum, so I just used the curvature of the regularization term in the objective (where the curvature is the smallest eigenvalue of the Hessian at the optimum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6a462c23-7f1c-4fa8-abc6-3e908c9c3544",
    "deletable": false
   },
   "source": [
    "Check the parameters that the model learned.  Which ones appear to be most important for doing well on this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9ae32242-95ae-4ebc-a1da-b12037f379fc",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "436fc1f1-7c52-4c39-a8e8-0fb121c4e4d2",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "viterbi_agent.model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "8fc7a371-908c-4cff-8b99-fa6bac4fc13a",
    "deletable": false
   },
   "source": [
    "Another question is how well we would have done in the semi-supervised training setting.  \n",
    "`train-partial.tsv` provides a partially observed version of `train.tsv`, in which the `yy` column has been turned into an `oo` column.\n",
    "\n",
    "This is the same setting for which the Expectation-Maximization algorithm is used.  Like EM, our training algorithm similarly tries to (locally) maximize the \"incomplete-data log-likelihood\" $\\sum_{n=1}^N \\log p_{\\boldsymbol{\\theta}}(\\mathbf{o}_n \\mid \\mathbf{x}_n)$ (minus a regularizer).  But we are simply applying stochastic gradient directly to that objective. \n",
    "\n",
    "This is a popular alternative to EM.  In fact, it turns out that computing the stochastic gradient is essentially the same computation as the E step.  Both compute a vector of feature expectations under $p_\\theta(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{o})$.  They just use this vector a little differently within their overall maximization algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a4049762-67bd-41be-9799-14dba144cae9",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "itr = iterate_data('train-partial') \n",
    "print(next(itr))            \n",
    "next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "g.cell_uuid": "6f6313c6-4e57-4fc4-a7f6-b5db3eca59d0",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Make a new model and train it on the partial version of the dataset\n",
    "model2 = TrainableLoglinearStressModel(regularization_coeff=c, num_examples=N)  # new copy\n",
    "viterbi_agent2 = ViterbiAgent(task, model2) \n",
    "print('Initial params: {}'.format(viterbi_agent2.params))\n",
    "\n",
    "trainset2 = list(iterate_data('train-partial'))\n",
    "# assert N == len(trainset2)\n",
    "\n",
    "trainer.train(model2, trainset2)  # use the same trainer (hyperparameters, etc.)\n",
    "print('Average dev reward after training: {}'.format(viterbi_agent2.test(iterate_data('dev'))))\n",
    "print('Params after semi-supervised training: {}'.format(viterbi_agent2.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "502d9fbd-8612-43a6-ba68-e5683661a486",
    "deletable": false
   },
   "source": [
    "Let's look more systematically at what happens to the quality of the *model* (average log-probability of the truth) and the quality of the *agent* (average reward) when we train.  The systematic experiment below is run on a small amount of data, but you could play around and change that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "a403a4cb-5c01-43b8-9dbd-cd8027d67fe1",
    "deletable": false
   },
   "source": [
    "* Different lines below show what happens when we evaluate on examples from different datasets: `train`, `train-partial`, and `dev`. \n",
    "What do you learn by comparing these numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "067a9531-458a-43cb-ab3c-2cd726235df0",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1f7fad77-52db-4a34-b8fe-b8f38800fd40",
    "deletable": false
   },
   "source": [
    "* Does the trained probability model the training data well? (If not, we are \"underfitting\" the training data. We need a better model or less regularization.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6525a9a6-90db-46a5-9471-4d54fa61c51e",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ee68bdf1-cd9f-4c02-833a-29e1b018a99f",
    "deletable": false
   },
   "source": [
    "* Does training allow the model to generalize to held-out dev data well? (If we perform worse on dev data than on training data, then we are \"overfitting\" the training data. We need more regularization.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d7d7c3b9-b899-410f-b754-ed2639538c61",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b8fd88c8-0835-4477-a7b1-d6e094993fc2",
    "deletable": false
   },
   "source": [
    "* Did semi-supervised training (last section of the output) work as well as supervised training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "fcef1fd5-75d3-4e55-a2a1-8874dd25215b",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "87dbcc98-6c56-42ae-9319-e81ed4bd0b95",
    "deletable": false
   },
   "source": [
    "If you're curious, feel free to extend the experiment to look how performance is affected by other decisions: the regularization coefficient, the structure of your model, the amount of training data, the hyperparameters for the SGD method, random reruns of SGD, etc. If you choose to look into these questions, you can discuss here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fc5db55f-8214-42b5-a36d-641074e9812c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def experiment(task, agent_classes=[], max_test_examples=None, max_train_examples=None):\n",
    "    for i, train in enumerate(['train','train-partial']):\n",
    "        \n",
    "        trainset = list(iterate_data(train,max_examples=max_train_examples))\n",
    "        model = TrainableLoglinearStressModel(regularization_coeff=c, num_examples=len(trainset))\n",
    "        agents = [ constructor(task, model) for constructor in agent_classes ]\n",
    "        \n",
    "        def print_results():\n",
    "            for test in ['train','train-partial','dev']:\n",
    "                testset = list(iterate_data(test, max_examples=max_test_examples))\n",
    "                results = (model.logprob_per_example(testset),\n",
    "                           None if test=='train-partial'   # no answers there to score\n",
    "                           else [agent.test(testset) for agent in agents])\n",
    "                print('(logprob, rewards) per {} example = {}'.format(test, results))\n",
    "                \n",
    "        if i==0:  # for first version of train only, to avoid redundancy\n",
    "            print('Model quality before training')\n",
    "            print_results()\n",
    "        print('\\nTraining set: {}'.format(train))\n",
    "        trainer.train(model, trainset)\n",
    "        print('Model quality after training')\n",
    "        print_results()\n",
    "\n",
    "experiment(task, [ViterbiAgent], max_test_examples=300, max_train_examples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ffb07935-7d2f-41b3-bb04-0e1e5e4d2d0e",
    "deletable": false
   },
   "source": [
    "## A new reward function\n",
    "\n",
    "So far we have been using a reward function that only rewards us when we are *exactly* right.  However, some task settings might offer \"partial credit.\"\n",
    "\n",
    "The *Hamming distance* between two strings of the same length is the number of positions in which they differ.  Our new reward function will be loosely based on Hamming distance between our prediction `aa` and the true string `yy`, with 3 changes:\n",
    "* Hamming distance is really a *loss*, since larger distance is bad.  So we will negate it to get a reward.  \n",
    "  Now the best possible reward is 0, and discrepancies between `aa` and `yy` are punished with *negative* reward.\n",
    "* We make the function asymmetric.  An incorrectly stressed vowel (uppercase letter in `aa`) is punished with -1, \n",
    "  but an incorrectly unstressed vowel (lowercase letter in `aa`) is punished with -0.3.  Thus, it would be better \n",
    "  to err on the side of lowercase.\n",
    "* We normalize by the length of `yy`.  Thus, no matter how long an example string is, its reward is \n",
    "  bounded between -1 and 0, just as it was formerly bounded between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f4b81a2c-b856-4338-996d-78d6a2259a7b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "a = LoglinearStressModel()\n",
    "b = LoglinearStressModel()\n",
    "a.params += 1\n",
    "b.params += 2\n",
    "print(a.params)\n",
    "print(b.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "3b576fbb-f9da-49b5-80c6-3bffe615b82a",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class HammingTask(StressTask):\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        assert yy is not None\n",
    "        return sum(0 if aa[t] == yy[t] else (-.3 if aa[t] in 'aeiou' else -1.0) for t in range(len(aa))) / len(yy)\n",
    "    \n",
    "    def reward_threshold(self, *, xx):\n",
    "        return 0    # best possible reward\n",
    "\n",
    "hamming_task = HammingTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "0718b2c3-133d-4bd8-9078-84cb4d19f345",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "hamming_task.reward(aa='tEst', xx='test', yy='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "294e5fa5-4dc2-47c6-a416-e411aa9b0c52",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "hamming_task.reward(aa='test', xx='test', yy='tEst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "cfaa29ed-0628-4c8d-83f4-ae4266378598",
    "deletable": false
   },
   "source": [
    "## Reward-infused decoding\n",
    "\n",
    "Our old decision rule \u2014 the Viterbi decoder \u2014 tries to maximize the old reward (0 or 1).\n",
    "Let's change the decision rule to try to optimize its prediction for the new (arbitrary) reward function instead.\n",
    "This would be a \"Bayes rule\" if we knew the true probability distribution $p^*$:\n",
    " $$ \\mathrm{argmax}_{\\mathbf{a} \\in \\boldsymbol{\\mathcal{A}}_{\\mathbf{x}}} \\sum_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x},\\mathbf{o}}} p^*(\\mathbf{y} \\mid \\mathbf{x}, \\mathbf{o}) \\cdot R(\\mathbf{a} \\mid \\mathbf{x},\\mathbf{y}) $$\n",
    " \n",
    "Of course, we will have to use our trained probability model $p_\\boldsymbol{\\theta}$ instead of $p^*$.  \n",
    "Go ahead and implement a brute-force version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "104d222b-2408-4497-b349-e3b235e91c93",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class BayesAgent(DecisionAgent):\n",
    "    \"\"\"\n",
    "    Try to make the decision that minimizes the Bayes risk \n",
    "    (or in positive terms, maximizes the Bayes value).\n",
    "    \"\"\"\n",
    "    \n",
    "    def decision(self, *, xx, oo=None):\n",
    "        # Warning: Don't inadvertently recompute the same normalizer many times!  That's inefficient.\n",
    "        ### STUDENTS START\n",
    "        ### Bayes min risk decoding\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "41248172-b94e-4307-8812-d49c96746af9",
    "deletable": false
   },
   "source": [
    "Test how well the Bayes agent performs with our Hamming distance reward.  Notice that the agent is simply consulting the `model` we've already trained and making predictions in a different way.  We don't have to retrain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "98bbce5b-5e92-4fe6-89c6-07390a9f4860",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "hamming_agent = BayesAgent(hamming_task, model)\n",
    "hamming_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "86b3a88d-0fb6-4f56-bcb0-2232d34c8971",
    "deletable": false
   },
   "source": [
    "How well would our Viterbi agent do on the same task, i.e., when evaluated on the new reward function?  Again, the model doesn't change, and the Viterbi rule makes the same decisions as before; we're just rewarding those decisions with a different formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "dee97865-c767-47d3-ad3d-74d6c93caa2b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "ViterbiAgent(hamming_task, model).test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "63979035-fa25-46ff-86c9-d86523cb9111",
    "deletable": false
   },
   "source": [
    "Notice that the Bayes agent is a lot slower.  That's because it has to maximize over all possible actions $\\mathbf{a}$ in the outer loop, where each is evaluated by an expectation over all possible gold answers $\\mathbf{y}$ in the inner loop.  As we'll see in the next assignment, for some reward functions the outer loop can be sped up by dynamic programming, and for some probability models the inner loop can be sped up by dynamic programming.\n",
    "\n",
    "Feel free to look at the examples where the predictions are different (it's only a couple of lines of Python, right?).  We might expect that the Bayes agent is more conservative about adding stress, due to the asymmetric reward.  Or it might be that the Viterbi string ends with a capital letter, but most of the other strings end with a lowercase letter, so the Bayes agent thinks it's safer to pick lowercase.  \n",
    "\n",
    "By the way, these new rewards look pretty good.  But maybe that's because they now include partial credit.  In fact, there's a large fraction of letters that we're never penalized on \u2014 we always get the consonants right, as well as the vowels that are observed in `dev.tsv`.  To know whether the results are actually impressive, we should compare with a simple baseline system.  For example, how much reward would the Viterbi or Bayes rule obtain with the default *initial* parameters of `LogLinearStressModel`?  Or with a uniform distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "1a2394e0-1083-4294-b7c4-5f209fb16766",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# experiment here with baselines!\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "933af9f3-326d-4e7a-aebf-3b6114f2dfc3",
    "deletable": false
   },
   "source": [
    "## *\"Crazy\"* reward function\n",
    "  \n",
    "A task setting is free to define any reward function that compares the prediction $\\mathbf{a}$ to the \"gold\" answer $\\mathbf{y}$. One of the most common reward functions in natural language processing is BLEU.  BLEU is primarily used in machine translation. It checks whether the n-grams in $\\mathbf{a}$ mostly appear in $\\mathbf{y}$.  It can work when $\\mathbf{a}$ and $\\mathbf{y}$ are different lengths, so it includes a \"brevity penalty\" to prevent $\\mathbf{a}$ from being very short and only including a few confident n-grams.  This reward function has become popular for scoring machine translation systems, as it has been shown to correlate with human preferences for translations, can be easily computed, allows \"partial credit\" when $\\mathbf{a}$ is mostly good output, and allows $\\mathbf{y}$ to be a set of good translations (written by different humans) instead of just one.\n",
    "\n",
    "In this homework, we will be implementing a slightly simplified version of BLEU (the smoothing method is simpler, as shown at $\\epsilon$ below).  BLEU computes the harmonic mean over $1 \\leq n \\leq 4$ of the precision of $\\mathbf{y}$'s n-grams.  It's still rewarding to match the shorter n-grams even when we fail to match any of the longer n-grams.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\#\\mathbf{y}_{\\mathbf{c}} &:= \\text{Number of instances of ngram $\\mathbf{c}$ inside string $\\mathbf{y}$} \\\\\n",
    "  \\text{ngram}_n &:= \\text{set of ngrams $n$ tokens long} \\\\\n",
    "  \\epsilon &:= .01 \\\\\n",
    "  p_n &= \\frac{\\max\\{\\sum_{\\mathbf{c} \\in \\text{ngram}_n} \\min\\{\\#\\mathbf{a}_{\\mathbf{c}}, \\#\\mathbf{y}_{\\mathbf{c}}\\}, \\epsilon \\} }{\\max\\left\\{\\sum_{\\mathbf{c} \\in \\text{ngram}_n} \\#\\mathbf{y}_\\mathbf{\\mathbf{c}}, 1\\right\\}} & \\textit{Precision with ``smoothing''} \\\\\n",
    "  \\textit{bp}(a, y) &= \\left\\{ \\begin{array}{cc} 1 & \\text{if }a \\ge y \\\\ e^{1 - a/y} & \\text{otherwise} \\end{array} \\right. & \\textit{brevity penalty} \\\\\n",
    "  R(\\mathbf{a} \\mid \\mathbf{y}) &:= \\text{exp}\\left( \\frac{1}{4} \\sum_{n=1}^4 \\log(p_n) \\right) \\cdot \\textit{bp}(\\text{len}(\\mathbf{a}), \\text{len}(\\mathbf{y}))\n",
    "  & \\textit{BLEU score (reward function)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "bdc21daa-af8a-4eb3-a51c-d844026cef32",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "### Helper functions for bleu\n",
    "from collections import Counter\n",
    "def ngrams(n, string):\n",
    "    grams = Counter()\n",
    "    for i in range(0, len(string) - n + 1):\n",
    "        grams[string[i:i+n]] += 1\n",
    "    return grams\n",
    "\n",
    "### Define more helper functions here ...\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "def bleu(*, aa, yy):\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    \n",
    "\n",
    "class BleuStressTask(StressTask):\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        assert yy is not None\n",
    "        return bleu(aa=aa, yy=yy)\n",
    "    \n",
    "    def reward_threshold(self, *, xx):\n",
    "        return 1   # maximum possible reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1ec942f3-2051-407d-a75a-1ac0ab85be0b",
    "deletable": false
   },
   "source": [
    "Sanity-check your BLEU implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ec21a271-1773-4171-bc15-8aaac8bbae83",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "bleu_task = BleuStressTask()\n",
    "assert bleu(aa='test', yy='test') == 1\n",
    "assert np.isclose(bleu(aa='TEST', yy='test'), .0045180100180492264)\n",
    "\n",
    "### STUDENTS START\n",
    "### Write additional tests for your bleu function\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5e05c9e3-0344-427c-b8f5-4ee7ba6b10f1",
    "deletable": false
   },
   "source": [
    "How well does the agent do at BLEU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "abbf639b-4093-43ce-94af-876a1c4c5d5e",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "bleu_agent = BayesAgent(bleu_task, model)\n",
    "bleu_agent.test(iterate_data('dev', max_examples=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "f0f4e392-840f-4a5b-b51d-b7c36528d8c7",
    "deletable": false
   },
   "source": [
    "## Speeding up the BLEU Implementation\n",
    "\n",
    "It now appears that our decision rule has become somewhat slow after making it compute the BLEU function on all possible predictions `aa`.  When building more complicated models, we will often have to put our engineering hats on and figure out how to make our programs run faster.\n",
    "\n",
    "First lets get a baseline for how fast our BLEU decoder is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "68fca30f-6051-455c-8cfa-6a28765afe75",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%time bleu_agent.test(iterate_data('dev', max_examples=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "762aa891-ca2b-4812-a4dd-75a894aa4433",
    "deletable": false
   },
   "source": [
    "Let's try and identify the slow functions using [`%prun`](http://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-prun).  This will generate a profile of all the functions that are called when running and how long each function takes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d2dfcba2-98df-46be-9b76-969a23f0496f",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%prun bleu_agent.test(iterate_data('dev', max_examples=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0121b006-4b91-4d49-a001-f6edf3517126",
    "deletable": false
   },
   "source": [
    "Now that you have identified which functions are *slow* we are going to use [Cython](https://cython.readthedocs.io/en/latest/) to make our program faster by compiling the slow functions into C.\n",
    "\n",
    "Cython uses Python-like syntax, but allows a few additional annotations, which allows Cython to compile a faster version.\n",
    "     \n",
    "#### Short Cython tutorial / hints\n",
    " 1. In our jupyter notebook, we can load Cython using `%load_ext cython`.  We can then use Cython inside of any jupyter cell by putting `%%cython` at the top of the cell.  \n",
    " 2. The parameter `%%cython -a` will turn on verbose mode which is helpful when trying to debug why our function is slow.  This will show the resulting C program that is generated from our Cython code.  Lines that are highlighted in <span style='background-color:yellow'>yellow</span> indicate that they are invoking a lot of python internals, and thus will be *generally slower*.\n",
    " 3. Adding types to parameters can help reduce the overhead of calling a function.  Try both of these expressions in a `%%cython -a` block\n",
    " ```cython\n",
    "%cython -a\n",
    " def multiply_by_2(a):\n",
    "      return a * 2\n",
    " cdef float multiply_by_2(float a):\n",
    "      return a * 2\n",
    " ```\n",
    " 4. Defining types on local variables can also help.  Some types you could use include `dict`, `int`, `float`.  Defining a range parameter as `int` will help Cython generate a C-style `for` loop.  Using `dict` lets Cython omit some extra checks when accessing the elements inside of a dictionary type.\n",
    " ```cython\n",
    "%cython -a\n",
    " cdef foo():\n",
    "      cdef int i\n",
    "      cdef dict d = {}\n",
    "      for i  in range(10):\n",
    "           d[i] = i\n",
    " ```\n",
    " 5. We can replace `np.exp` with `libc.math.exp` which will use the `exp` function defined in C's `math.h` instead of making a slower call to numpy.\n",
    " \n",
    "\n",
    "There is no *correct* answer to how fast your program should run.  You need to decide when your program is fast enough such that you can actually study the problems that you are interested in.  For this problem set, you should aim to get at least 2-3x faster that your baseline BLEU implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "1f78cb6d-c3c8-4812-be29-7351f657d0e8",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "0a8bb786-8c0f-4872-87ae-88d75340cc89",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "from libc.math cimport exp, log\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "### STUDENTS START\n",
    "### Helper functions for bleu\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "def faster_bleu(tuple yy, tuple aa):\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "861f8770-ee39-4549-94c4-fc8ad8251d25",
    "deletable": false
   },
   "source": [
    "Check that our new BLEU function is predicting the same as our old function.  Also define a few additional checks of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "cdc11b65-3163-4d3b-83ba-4cc870fc3f5d",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "assert bleu(yy=tuple('tEst'), aa=tuple('test')) == faster_bleu(yy=tuple('tEst'), aa=tuple('test'))\n",
    "\n",
    "### STUDENTS START\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "8a3f61ca-24c1-41e1-8023-eecb4d712564",
    "deletable": false
   },
   "source": [
    "Check how much faster the fast bleu function is compared to the baseline bleu function\n",
    "\n",
    "1. Baseline BLEU function runtime (seconds):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "371bf236-9ee0-40f8-9cf4-8701e81898bd",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "bfd16024-b9df-405d-a8a2-b5e0ddd6b0dc",
    "deletable": false
   },
   "source": [
    "2. Faster BLEU function runtime (seconds):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "596d713c-9d43-4db3-8951-b782bd0507a0",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b8c082b1-fe60-4ff8-b07a-5219bc164dd3",
    "deletable": false
   },
   "source": [
    "3. Performance improvement (faster/baseline, %):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "8af294dc-8aff-4909-9fb3-24e46a5c1692",
    "deletable": false
   },
   "source": [
    "**Answer:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "67216518-5df9-446f-9d99-9ba3de7ca9d3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class FasterBleuStressTask(BleuStressTask):\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        assert yy is not None\n",
    "        return faster_bleu(aa=aa, yy=yy)\n",
    "    \n",
    "faster_bleu_task = FasterBleuStressTask()\n",
    "\n",
    "faster_bleu_agent = BayesAgent(faster_bleu_task, model)\n",
    "%time faster_bleu_agent.test(iterate_data('dev', max_examples=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b66a15e0-635d-423c-8f89-f890931dfc62",
    "deletable": false
   },
   "source": [
    "Now that that our BLEU function is much faster, we can evaluate it over the entire dev set.  (Although really, 100 examples is often plenty for evaluation \u2014 just not for training.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "1393d190-4712-4dba-b83a-f4b114761d17",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "faster_bleu_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1a126e90-71d8-41b2-bae7-d0407e8b8a73",
    "deletable": false
   },
   "source": [
    "If you like, you could try including rerunning `experiment` from before on the BLEU task, and include the performance of the Viterbi, Hamming, and BLEU agents when measured by the BLEU reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "07a9cc91-de90-42af-9126-9489a1a4dc51",
    "deletable": false
   },
   "source": [
    "## Expectations under $p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x})$\n",
    "\n",
    "You may notice that we have used expected values in two ways:\n",
    "* A Bayes rule evaluates a plan $\\mathbf{a}$ for input $\\mathbf{x}$\n",
    "  according to its *expected reward*, \n",
    "  $$\\mathbb{E}_{\\mathbf{y}\\mid\\mathbf{x}}[R(\\mathbf{a} \\mid \\mathbf{x},\\mathbf{y})]\n",
    "  = \\sum_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}}} p_{\\boldsymbol{\\theta}}(\\mathbf{y} \\mid \\mathbf{x}) \\cdot R(\\mathbf{a} \\mid \\mathbf{x},\\mathbf{y})$$\n",
    "* The stochastic gradient of conditional log-likelihood from an example $(\\mathbf{x},\\mathbf{y})$ involves\n",
    "  the term \n",
    "  $$\\nabla_{\\boldsymbol{\\theta}} \\log Z(\\mathbf{x}) = \\mathbb{E}_{\\mathbf{y}\\mid\\mathbf{x}}[\\nabla_{\\boldsymbol{\\theta}} G_{\\boldsymbol{\\theta}}(\\mathbf{x},\\mathbf{y})] = \\sum_{\\mathbf{y} \\in \\boldsymbol{\\mathcal{Y}}_{\\mathbf{x}}} p_{\\boldsymbol{\\theta}}(\\mathbf{y} \\mid \\mathbf{x}) \\cdot  \\nabla_{\\boldsymbol{\\theta}} G_{\\boldsymbol{\\theta}}(\\mathbf{x},\\mathbf{y})$$\n",
    "\n",
    "These are the main two uses of (conditional) expectations.  Most other uses are just variants on the two above \u2014 *prediction* from the model and *training* the model's parameters.  \n",
    "\n",
    "(However, an additional use is to measure the model's posterior uncertainty about a quantity $f(\\mathbf{y})$, given $\\mathbf{x}$.  Common uncertainty measurements such as variance and entropy are actually expectations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "396c6014-a79f-4e2f-bc57-3e3922c172b9",
    "deletable": false
   },
   "source": [
    "### Estimating expectations by sampling from $p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x})$\n",
    "\n",
    "So far, we have been computing expectations by actually summing over all $\\mathbf{y} \\in \\mathcal{Y}_{\\mathbf{x}}$.  But this is often intractable.  An alternative is to approximate an expectation by sampling. That is, $\\mathbb{E}_{\\mathbf{y}\\mid\\mathbf{x}}[f(\\mathbf{y}]$ can be approximated as $\\text{mean}_i f(\\mathbf{y}_i)$ where the $\\mathbf{y}_i$ are drawn (at least approximately) from $p_\\theta(\\mathbf{y} \\mid \\mathbf{x})$.  Many expectations can be well-estimated by averaging over a rather small sample. \n",
    "\n",
    "Later we will study various methods for sampling exactly or approximately.  \n",
    "\n",
    "### Exact sampling\n",
    "\n",
    "Sampling exactly means that if $p_\\theta(\\mathbf{y} \\mid \\mathbf{x}) = \\frac{1}{4}$, then $\\mathbf{y}$ really does have a $\\frac{1}{4}$ probability of being drawn, so copies of $\\mathbf{y}$ will make up $\\frac{1}{4}$ of the sample on average.  Of course this doesn't mean that the sampling-based estimate of $\\mathbb{E}_{\\mathbf{y}\\mid\\mathbf{x}}[f(\\mathbf{y})]$ will be correct \u2014 it will vary depending on your random number generator.  But as the number of samples $\\rightarrow \\infty$, the average error of the estimate provably decreases $\\rightarrow 0$ (at least if $f(\\mathbf{Y})$ has finite variance).\n",
    "\n",
    "If exact sampling from a distribution can be done efficiently, it is usually just as efficient to compute the expectation exactly.  (For example, sampling and averaging may involve similar dynamic programming algorithms.)  Nonetheless, an exact sampler for an \"easy\" distribution might still be a useful ingredient in constructing an approximate sampler for a \"harder\" distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1b90a1b7-d809-43f9-95d9-f80dc032cc05",
    "deletable": false
   },
   "source": [
    "As a reference implementation, go back and implement [ProbabilityModel](#ProbabilityModel).`sampler`.  as a brute-force exact sampler.  That is, you'll explicitly compute $p_{\\boldsymbol{\\theta}}(\\mathbf{y} \\mid \\mathbf{x})$ for every $\\mathbf{y} \\in \\mathcal{Y}_{\\mathbf{x}}$ and then `yield` a stream of samples from that distribution.  You might find [np.random.choice](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.choice.html) useful.  Your implementation should also handle $p_{\\boldsymbol{\\theta}}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{o})$ if `oo` is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ac0da714-2365-41cb-a823-4a141a3fbf8b",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Make sure you also reevaluate the notebook cells for `BoltzmannModel`, `LoglinearModel`, and `LoglinearStressModel`, \n",
    "# now that you've updated their ancestor `ProbabilityModel`.\n",
    "\n",
    "model = LoglinearStressModel()             # an instance of the updated class\n",
    "xx, oo, yy = next(iterate_data('train'))   # get the first training example\n",
    "\n",
    "from itertools import islice     # lets us take the first N elements (or every Jth element) of an infinite stream\n",
    "for yy in islice(model.sampler(xx=xx, oo=oo), 10): \n",
    "    print(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d088b41f-1435-4f9b-8c96-565a0f0b4dee",
    "deletable": false
   },
   "source": [
    "So what is the expected number of stressed vowels in this example's output `yy`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "8317933b-8096-4243-afcb-600558eed377",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def count_stresses(yy):\n",
    "    \"Count the number of capitalized characters (stressed vowels) in string `yy`.\"\n",
    "    return len([y for y in yy if y.isupper()])\n",
    "\n",
    "for _ in range(8):  # 8 different estimates, each based on 30 *exact* samples\n",
    "   print(sum([count_stresses(yy) for yy in islice(model.sampler(xx=xx, oo=oo), 20)]) / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5fddc39e-d81b-40ae-a53b-83927081a748",
    "deletable": false
   },
   "source": [
    "### Approximate sampling\n",
    "\n",
    "Enumerating the entire exponentially large domain $\\mathcal{Y}_{\\mathbf{x}}$ can be slow, so now let's implement an alternative: Gibbs sampling.  This could be done for any `ProbabilityModel`, so go back to [ProbabilityModel](#ProbabilityModel) and fill the `approx_sampler` method with a Gibbs sampler.  The Gibbs sampler is a pretty good default choice for subclasses to inherit.\n",
    "\n",
    "The pseudo code for such a Gibbs sampler looks like this:\n",
    "  * $\\mathbf{y}$ = some initial legal guess of the output string (given $\\mathbf{x}$)\n",
    "  * Repeat forever:\n",
    "    * Randomly choose a position $j$ in the output string\n",
    "      * For each legal new value $y$ for $y_j$ \n",
    "        * temporarily set $y_j = y$\n",
    "        * let $\\tilde{q}(y) = \\tilde{p}_\\theta(\\mathbf{y} \\mid \\mathbf{x})$\n",
    "      * Draw $y$ from a normalized version of $\\tilde{q}$ and set $y_j = y$\n",
    "      * `yield` $\\mathbf{y}$\n",
    "\n",
    "with the obvious modifications to condition throughout on $\\mathbf{o}$ if `oo` is specified.  \n",
    "\n",
    "Note that the length of $\\mathbf{y}$ never changes, which is okay since our setup assumes that all legal output strings have the same length.  In general, a Gibbs sampler only works on a fixed-length vector of random variables: $\\mathbf{Y} = (Y_1,\\ldots,Y_J)$.  (Going beyond this requires devising a fancier MCMC method for your specific problem.)  A common simplification is to repeatedly loop through $j = 1,\\ldots,J$ rather than selecting $j$ randomly at each iteration.  \n",
    "\n",
    "In any case, the algorithm above provides an iterator over an infinite stream of (non-IID) samples $\\mathbf{y}_n: n=1,2,\\ldots$.  As $n \\rightarrow \\infty$, the sampling distribution of $\\mathbf{y}_n$ gets closer and closer to $p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x})$.\n",
    "\n",
    "You can estimate $\\mathbb{E}_{\\mathbf{y}\\mid\\mathbf{x}}[f(\\mathbf{y})]$ by averaging over\n",
    "some of these samples \u2014 for example, all of the first $N$ samples (see [One Long Run](http://users.stat.umn.edu/~geyer/mcmc/one.html)), or perhaps only every $J$th or every $(5\\cdot J)$th sample simply to reduce the\n",
    "number of calls to $f$ (since nearby samples in the stream are similar to one another anyway).\n",
    "Ideally, `ProbabilityModel` would provide an `expectation_approx` method that computes an \n",
    "approximate expectation in this way.  (As well as an exact `expectation` method that \n",
    "uses an exhaustive iterator over the exponentially large space $\\mathcal{Y}_{\\mathbf{x}}$.)\n",
    "\n",
    "*Hints:* Use `iterate_yy` (or possibly `iterate_y`) to make your initial guess, and use `iterate_y` to propose modifications.  In the case of `StressTask`, the Gibbs sampler could be made more efficient, so feel free to override your implementation in `LoglinearStressModel`.  (In `StressTask`, $q$ is a distribution over at most two possibilities \u2014 capital and lowercase versions of $x_j$.  And for many positions $j$, there is just *one* possibility \u2014 if $x_j$ is a consonant or $o_j$ specifies the value of $y_j$ \u2014 so you don't have to visit that position $j$ at all.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "fa0f89e0-a91a-48d2-b20c-9a27b81f10bd",
    "deletable": false
   },
   "source": [
    "Check the behavior of `approx_sampler`.  Note how strongly correlated successive samples are, since at most one character is different.  This reduces the effective sample size \u2014 we're getting pretty much the same `yy` over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "95e23c20-4217-42f3-8d16-e13c9e851f19",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "for yy in islice(model.approx_sampler(xx=xx, oo=oo), 10): \n",
    "    print(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6d6f2c07-bfb0-4bd4-957f-1f169d5ecadf",
    "deletable": false
   },
   "source": [
    "To reduce the correlation between successive samples, let's try printing only every $J$th sample, where $J=|\\mathbf{x}|$, so we are printing a new sample only after every \"sweep\" through all positions $j$.  This should look somewhat more like the exact sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "5d384cfc-29cd-4224-9868-5eccab4cd164",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "J = len(xx)\n",
    "for yy in islice(model.approx_sampler(xx=xx, oo=oo), J, 10*J, J): \n",
    "    print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "eac3a88b-819b-4b51-9d6f-794b1931837c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "for _ in range(8):  # 8 different estimates, each based on 20 *approximate* samples (spaced J apart but still correlated)\n",
    "   print(sum([count_stresses(yy) for yy in islice(model.approx_sampler(xx=xx, oo=oo), J, 20*J, J)]) / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "69273462-73f6-4b62-a9e2-3c4774a2c464",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "for _ in range(8):  # 8 different estimates, each based on 200 *correlated* *approximate* samples\n",
    "   print(sum([count_stresses(yy) for yy in islice(model.approx_sampler(xx=xx, oo=oo), 200)]) / 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e74baa5f-d787-402b-bf60-5027f7f605c9",
    "deletable": false
   },
   "source": [
    "### Comparing the samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "bc609bb7-7ad1-426d-948e-b65d12ddd8d2",
    "deletable": false
   },
   "source": [
    "In principle, you could use the approximate sampler to speed up the expectations used during training and when computing the decision rule.  \n",
    "\n",
    "But to check that the exact and approximate samplers are doing roughly the same thing, let's estimate the Kullback-Leibler divergence between the distributions that they're sampling from.  The true distribution is $p_\\boldsymbol{\\theta}(\\mathbf{y} \\mid \\mathbf{x})$.  The approximate sampler is implicitly drawing from some distribution $q(\\mathbf{y} \\mid \\mathbf{x})$ that is harder to describe.  For a fixed $\\mathbf{x}$, we can abbreviate these as $p_\\boldsymbol{\\theta}(\\mathbf{y})$ and $q(\\mathbf{y})$, and the KL divergence between these is\n",
    "$$\\text{KL}(p_\\boldsymbol{\\theta} \\mid\\mid q) = \\mathbb{E}_{\\mathbf{y} \\sim p_\\theta}[\\log_2 \\frac{p_\\boldsymbol{\\theta}(\\mathbf{y})}{q(\\mathbf{y})}]$$\n",
    "This is clearly 0 if the two distributions are equal.\n",
    "\n",
    "You can use brute force to compute the above expectation under $p_\\boldsymbol{\\theta}$.\n",
    "To get the term $q(\\mathbf{y})$, you should take a large sample from $q$ and count the fraction of times that $\\mathbf{y}$ occurred.  Unfortunately, if your sample is too small, you might divide by 0.  Python's `Counter` class is useful for collecting these counts.\n",
    "\n",
    "If your Gibbs sampler $q$ is working correctly, its KL divergence from $p_\\boldsymbol{\\theta}$ on your trained `LoglinearStressModel` should be $< .1$ bit on average (when conditioning on some `xx` or `(xx,oo)` from our dataset).  If you modify your code to replace the approximate sampler $q$ with the (possibly slower) exact sampler, then the (estimated) KL divergence should be $\\approx 0$, which is a good test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d2f427d3-7ce7-4bf8-bb2a-72c66fb4c3e5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def kl(model, *, xx, oo=None, num_q_samples=5000):\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c8399816-8ceb-411d-a229-2784a4e9ab14",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "kl(model, xx=xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "5bce0e04-de54-40fe-8aee-d2ef2ced2427",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "sum([kl(model, xx=xx) for xx, oo, yy in iterate_data('train', max_examples=100)]) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5ef2e677-ed1b-4c84-81fe-d45b187c11e1",
    "deletable": false
   },
   "source": [
    "### Using the sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "b14ec3da-8c63-4ffa-9536-01ec5bed12f9",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class SamplingBayesAgent(DecisionAgent):\n",
    "    \"\"\"\n",
    "    A version of BayesAgent that evaluates each plan by sampling.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, num_samples=100, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def decision(self, *, xx, oo=None):\n",
    "        # Efficiency tip: Collect a single set of samples and reuse it to evaluate each action in turn.  \n",
    "        # Efficiency tip: Use a Counter to consolidate duplicate samples.\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "9e776cd1-c0a5-4061-bea7-1b5ebc599687",
    "deletable": false
   },
   "source": [
    "Using our trained model, let's see whether it makes equally good decisions on `hamming_task`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d9d9ea96-942b-4229-b231-8270261a0921",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Repeated from before \n",
    "hamming_agent = BayesAgent(hamming_task, model)\n",
    "hamming_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "396a2832-acee-43ac-b93c-88dcfda5a94a",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "hamming_agent = SamplingBayesAgent(hamming_task, model, num_samples=20)\n",
    "hamming_agent.test(iterate_data('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0ee4632c-e129-408c-aca2-28bd81292d62",
    "deletable": false
   },
   "source": [
    "Was this faster?  Were the decisions as good?  What if you change the number of samples per decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "57eb018e-6ca8-47bb-836a-ba2b2ac8f365",
    "deletable": false
   },
   "source": [
    "**Discussion:** <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "8ba5abe4-5f78-489a-bd7a-86ff2909b846",
    "deletable": false
   },
   "source": [
    "# The final test!\n",
    "\n",
    "Throughout this homework we have implemented a number of different setups, and we have been tuning, debugging and developing these models using our *development* set.  Now that we have reached the end, choose a task setting that you like.  Choose **one** agent for that setting (including **one** model and **one** decision rule), and choose **one** training procedure that you use to train it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "73d5b313-9946-4189-abb0-1e8e4b58b9c0",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "### STUDENTS START\n",
    "### my_chosen_task = ????\n",
    "### my_chosen_model = ????\n",
    "### my_chosen_agent = ????\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "my_chosen_trainer.train(my_chosen_agent, iterate_data('train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "7198df2a-0c9a-44ed-a11c-315a5312a198",
    "deletable": false
   },
   "source": [
    "Now run your trained agent on the test data.  Only execute this cell once!  Don't go back and change your choices after you see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "8fc5d48a-4191-41bb-ba16-b275492e67b8",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "my_chosen_agent.test(iterate_data('test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}